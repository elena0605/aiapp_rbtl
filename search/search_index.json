{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#rbtl-graphrag-documentation","title":"RBTL GraphRAG Documentation","text":""},{"location":"#introduction","title":"Introduction","text":"<p>RBTL GraphRAG is a web-based portal that provides a natural language interface for querying Neo4j graph databases, enabling users to explore complex graph data without needing to be technical experts themselves. The system delivers an intuitive chat-based experience where users can ask questions in plain English and receive both structured query results and conversational summaries. The AI does its magic in the background - deciding on the intent of the user questions, and calling the applicable tools(agents) that handle: cypher-to-text queries, data visualization or advanced graph algorithms. The portal includes features such as personal chat interface, query result visualization, a knowledge base for organizing query examples (for improving the AI capabilities), and real-time agent tracking that shows where queries are routed in the agentic system.</p> <p>The platform is designed for analysts, researchers, and business users who need to extract insights from graph databases but may not have expertise in graph query languages. By abstracting away the complexity of Cypher syntax, the system democratizes access to graph data, allowing domain experts to focus on asking the right questions rather than learning database-specific query languages. The multi-user architecture supports separate chat sessions for different testers or team members, with each user maintaining their own conversation history and favorite queries, making it suitable for collaborative environments where multiple stakeholders need to explore the same graph data from different perspectives.</p> <p>At its core, RBTL GraphRAG leverages several sophisticated AI capabilities to deliver intelligent query generation and analysis. The system uses large language models (LLMs) to convert natural language questions into accurate Cypher queries, with schema-aware prompt engineering that ensures generated queries respect the Neo4j database structure. An Graph Analytics Agent extends this functionality by intelligently routing certain questions to graph data science algorithms\u2014such as community detection (Leiden), influence ranking (ArticleRank) or visualizing the Cypher obtained data. The platform also maintains a knowledge base of categorized query examples stored in MongoDB and synchronized with Neo4j's vector store, enabling few-shot learning that helps the LLM generate more accurate queries by referencing similar past questions. Full observability is provided through Langfuse integration, which traces all LLM calls, prompt versions, and tool invocations, giving administrators visibility into system performance and query patterns.</p>"},{"location":"#how-to-use-these-docs","title":"How to Use These Docs","text":"<ul> <li>Start with Getting Started to run the dockerized application locally.</li> <li>Explore the Architecture section for diagrams and service breakdowns.</li> <li>Review Docker Deployment for local and cloud container deployment.</li> <li>Consult Operations for environment-specific deployment guides.</li> <li>See Azure Production Deployment for cloud deployment with Docker containers.</li> </ul>"},{"location":"DOCKER_DEPLOYMENT/","title":"Docker Deployment","text":""},{"location":"DOCKER_DEPLOYMENT/#docker-deployment-guide","title":"Docker Deployment Guide","text":"<p>This guide explains how to build and deploy the RBTL GraphRAG application using Docker.</p>"},{"location":"DOCKER_DEPLOYMENT/#architecture","title":"Architecture","text":"<p>The application consists of two Docker containers:</p> <ul> <li>Backend: FastAPI application (Python 3.13)</li> <li>Frontend: Next.js application (Node.js 18)</li> </ul>"},{"location":"DOCKER_DEPLOYMENT/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose installed</li> <li><code>.env</code> file with all required environment variables</li> </ul>"},{"location":"DOCKER_DEPLOYMENT/#quick-start","title":"Quick Start","text":""},{"location":"DOCKER_DEPLOYMENT/#1-build-and-run-with-docker-compose","title":"1. Build and Run with Docker Compose","text":"<pre><code># Build and start all services\ndocker-compose up --build\n\n# Or run in detached mode\ndocker-compose up -d --build\n</code></pre> <p>The application will be available at: - Frontend: http://localhost:3003 (port 3003 to avoid conflicts) - Backend API: http://localhost:8001 (port 8001 to avoid conflicts) - API Docs: http://localhost:8001/docs</p> <p>Note: Ports are mapped to avoid conflicts with: - Local development (backend: 8000, frontend: 3002) - Langfuse (3001)</p>"},{"location":"DOCKER_DEPLOYMENT/#2-stop-services","title":"2. Stop Services","text":"<pre><code>docker-compose down\n</code></pre>"},{"location":"DOCKER_DEPLOYMENT/#building-individual-images","title":"Building Individual Images","text":""},{"location":"DOCKER_DEPLOYMENT/#backend-image","title":"Backend Image","text":"<pre><code>docker build -f backend/Dockerfile -t rbtl-graphrag-backend:latest .\n</code></pre>"},{"location":"DOCKER_DEPLOYMENT/#frontend-image","title":"Frontend Image","text":"<pre><code>docker build -f frontend/Dockerfile \\\n  --build-arg NEXT_PUBLIC_API_URL=http://localhost:8000 \\\n  -t rbtl-graphrag-frontend:latest .\n</code></pre>"},{"location":"DOCKER_DEPLOYMENT/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file in the project root with:</p> <pre><code># Environment Selection\nENVIRONMENT=production  # Set to \"development\" for local development\n\n# Neo4j (Production)\nNEO4J_URI=bolt+s://your-db-id.databases.neo4j.io\nNEO4J_USER=neo4j\nNEO4J_PASSWORD=your-password\nNEO4J_DATABASE=neo4j\n\n# Neo4j (Development - Optional)\n# When ENVIRONMENT=development, these will be used instead\n# For Docker: use host.docker.internal instead of localhost/127.0.0.1\n# NEO4J_URI_DEV=bolt://host.docker.internal:7687\n# NEO4J_USER_DEV=neo4j\n# NEO4J_PASSWORD_DEV=local-password\n# NEO4J_DATABASE_DEV=neo4j\n\n# OpenAI\nOPENAI_API_KEY=sk-proj-...\nOPENAI_MODEL=gpt-4o\n\n# Langfuse (Production)\nLANGFUSE_HOST=https://cloud.langfuse.com\nLANGFUSE_PUBLIC_KEY=pk-lf-...\nLANGFUSE_SECRET_KEY=sk-lf-...\nPROMPT_LABEL=production\n\n# Langfuse (Development - Optional)\n# When ENVIRONMENT=development, these will be used instead\n# LANGFUSE_HOST_DEV=http://localhost:3001\n# LANGFUSE_PUBLIC_KEY_DEV=pk-lf-dev-...\n# LANGFUSE_SECRET_KEY_DEV=sk-lf-dev-...\n\n# MongoDB (Production)\nMONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/?retryWrites=true&amp;w=majority\nMONGODB_DB=rbl\n# Alternative: MONGODB_DATABASE=rbl (both work)\n\n# MongoDB (Development - Optional)\n# When ENVIRONMENT=development, these will be used instead\n# For Docker: use host.docker.internal instead of localhost\n# MONGODB_URI_DEV=mongodb://airflow:tiktok@host.docker.internal:27017\n# MONGODB_DB_DEV=social_media\n# Alternative: MONGODB_DATABASE_DEV=social_media (both work)\n\n# Frontend\nNEXT_PUBLIC_API_URL=http://localhost:8000\n\n# Optional\nENABLE_ANALYTICS_AGENT=false\n</code></pre>"},{"location":"DOCKER_DEPLOYMENT/#environment-switching","title":"Environment Switching","text":"<p>The application supports switching between development and production environments using the <code>ENVIRONMENT</code> variable in your <code>.env</code> file.</p> <p>How it works: - Set <code>ENVIRONMENT=development</code> to use local databases and services - Set <code>ENVIRONMENT=production</code> (or omit it) to use production credentials - <code>_DEV</code> suffixed variables are optional - if not set, the app falls back to production values</p> <p>Example: Local Development Setup </p><pre><code>ENVIRONMENT=development\n\n# Production (for reference, won't be used)\nNEO4J_URI=neo4j+s://prod-db.databases.neo4j.io\nMONGODB_URI=mongodb+srv://prod-cluster...\n\n# Development (will be used)\n# Note: Use host.docker.internal for Docker containers to access host services\nNEO4J_URI_DEV=bolt://host.docker.internal:7687\nNEO4J_USER_DEV=neo4j\nNEO4J_PASSWORD_DEV=local-password\nNEO4J_DATABASE_DEV=neo4j\nMONGODB_URI_DEV=mongodb://airflow:tiktok@host.docker.internal:27017\nMONGODB_DB_DEV=social_media\nLANGFUSE_HOST_DEV=http://host.docker.internal:3000\n</code></pre><p></p> <p>Docker Compose automatically passes all environment variables from your <code>.env</code> file to the containers, so environment switching works seamlessly with Docker.</p>"},{"location":"DOCKER_DEPLOYMENT/#switching-between-environments","title":"Switching Between Environments","text":"<p>To switch from one environment to another, follow these steps:</p> <p>Step 1: Update <code>.env</code> file</p> <p>Edit your <code>.env</code> file and change the <code>ENVIRONMENT</code> variable:</p> <pre><code># To switch to development\nENVIRONMENT=development\n\n# To switch to production\nENVIRONMENT=production\n</code></pre> <p>Step 2: Restart the backend container</p> <p>After changing <code>ENVIRONMENT</code>, restart the backend container to load the new environment:</p> <pre><code># Simple restart (works if container is already running)\ndocker-compose restart backend\n</code></pre> <p>Or, if you want to ensure all environment variables are reloaded:</p> <pre><code># For production mode\ndocker-compose up -d --force-recreate backend frontend\n\n# For development mode\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --force-recreate backend frontend\n</code></pre> <p>Note: You don't need to stop containers first. The <code>--force-recreate</code> flag will recreate the container with the new environment variables.</p> <p>Alternative: Full restart (if simple restart doesn't work)</p> <p>If you need to fully stop and recreate:</p> <pre><code># If you started with production mode (docker-compose up)\ndocker-compose down\ndocker-compose up -d --force-recreate\n\n# If you started with development mode (docker-compose -f docker-compose.yml -f docker-compose.dev.yml up)\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml down\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --force-recreate\n</code></pre> <p>Step 3: Verify the switch</p> <p>Check that containers are using the correct environment:</p> <pre><code># Check backend logs to see which environment is active\ndocker-compose logs backend | grep -i environment\n\n# Or check environment variables in the container\ndocker-compose exec backend env | grep ENVIRONMENT\n</code></pre> <p>Quick Reference: Switching Commands</p> <pre><code># Switch to Development\n# 1. Edit .env: ENVIRONMENT=development\n# 2. Run (simplest method):\ndocker-compose restart backend\n\n# Or with force recreate (ensures env vars are reloaded):\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --force-recreate backend frontend\n\n# Switch to Production\n# 1. Edit .env: ENVIRONMENT=production\n# 2. Run (simplest method):\ndocker-compose restart backend\n\n# Or with force recreate (ensures env vars are reloaded):\ndocker-compose up -d --force-recreate backend\n</code></pre>"},{"location":"DOCKER_DEPLOYMENT/#understanding-the-two-concepts","title":"Understanding the Two Concepts","text":"<p>There are two independent concepts that can be mixed and matched:</p> <p>1. <code>ENVIRONMENT</code> variable (in <code>.env</code> file) - Controls which databases/credentials to use - <code>ENVIRONMENT=development</code> \u2192 uses <code>NEO4J_URI_DEV</code>, <code>MONGODB_URI_DEV</code>, <code>LANGFUSE_HOST_DEV</code> - <code>ENVIRONMENT=production</code> \u2192 uses <code>NEO4J_URI</code>, <code>MONGODB_URI</code>, <code>LANGFUSE_HOST</code></p> <p>2. Docker Compose files - Controls how the code runs (hot-reload, volume mounts, build mode) - <code>docker-compose.yml</code> \u2192 Production Docker mode (no hot-reload, code baked into image) - <code>docker-compose.yml + docker-compose.dev.yml</code> \u2192 Development Docker mode (hot-reload, volume mounts)</p> <p>Important: Both modes can run locally on your machine or on remote servers. The difference is not about location, but about: - Production Docker mode: Optimized for deployment (code baked in, no hot-reload, smaller images) - Development Docker mode: Optimized for active coding (hot-reload, volume mounts, easier debugging)</p> <p>The Difference Between the Two Commands:</p> <p></p><pre><code># Command 1: Production Docker mode\ndocker-compose up -d --force-recreate\n</code></pre> - Uses only <code>docker-compose.yml</code> - Code is baked into the Docker image (no volume mounts) - No hot-reload - changes require rebuild - Backend runs: <code>uvicorn</code> (production command) - Frontend runs: Next.js production build - BUT still respects <code>ENVIRONMENT</code> variable for database selection<p></p> <p></p><pre><code># Command 2: Development Docker mode\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --force-recreate backend frontend\n</code></pre> - Uses both <code>docker-compose.yml</code> + <code>docker-compose.dev.yml</code> (dev overrides) - Code is mounted as volumes (live code from your filesystem) - Hot-reload enabled - changes reflect immediately - Backend runs: <code>uvicorn --reload</code> (auto-reloads on file changes) - Frontend runs: <code>npm run dev</code> (Next.js dev server) - ALSO respects <code>ENVIRONMENT</code> variable for database selection<p></p> <p>Possible Combinations:</p> ENVIRONMENT Docker Mode What Happens <code>development</code> Production (<code>docker-compose up</code>) Uses dev databases, but no hot-reload <code>development</code> Development (<code>docker-compose -f ... -f docker-compose.dev.yml up</code>) Uses dev databases + hot-reload <code>production</code> Production (<code>docker-compose up</code>) Uses prod databases, no hot-reload <code>production</code> Development (<code>docker-compose -f ... -f docker-compose.dev.yml up</code>) Uses prod databases + hot-reload (unusual) <p>Most Common Use Cases:</p> <ul> <li>Local development with hot-reload: <code>ENVIRONMENT=development</code> + dev Docker mode</li> <li>Testing against production databases: <code>ENVIRONMENT=production</code> + dev Docker mode</li> <li>Production deployment: <code>ENVIRONMENT=production</code> + production Docker mode</li> </ul> <p>Important Notes: - \u2705 <code>docker-compose restart backend</code> is the simplest method and usually works - \u2705 <code>--force-recreate</code> ensures environment variables are fully reloaded (use if restart doesn't work) - \u2705 Containers will automatically reconnect to the correct databases based on the <code>ENVIRONMENT</code> variable - \u2705 No code changes needed - just update <code>.env</code> and restart/recreate the container - \u2705 Database names switch automatically:   - Development: Neo4j uses <code>neo4j</code> database, MongoDB uses <code>social_media</code> database   - Production: Both Neo4j and MongoDB use <code>rbl</code> database</p>"},{"location":"DOCKER_DEPLOYMENT/#cloud-deployment","title":"Cloud Deployment","text":""},{"location":"DOCKER_DEPLOYMENT/#push-to-container-registry","title":"Push to Container Registry","text":"<pre><code># Tag images\ndocker tag rbtl-graphrag-backend:latest your-registry/rbtl-graphrag-backend:latest\ndocker tag rbtl-graphrag-frontend:latest your-registry/rbtl-graphrag-frontend:latest\n\n# Push to registry\ndocker push your-registry/rbtl-graphrag-backend:latest\ndocker push your-registry/rbtl-graphrag-frontend:latest\n</code></pre>"},{"location":"DOCKER_DEPLOYMENT/#azure-container-apps","title":"Azure Container Apps","text":"<p>The images can be deployed to Azure Container Apps as described in the Azure Deployment Guide.</p>"},{"location":"DOCKER_DEPLOYMENT/#kubernetes","title":"Kubernetes","text":"<p>Example deployment manifests:</p> <pre><code># backend-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rbtl-graphrag-backend\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: rbtl-graphrag-backend\n  template:\n    metadata:\n      labels:\n        app: rbtl-graphrag-backend\n    spec:\n      containers:\n      - name: backend\n        image: your-registry/rbtl-graphrag-backend:latest\n        ports:\n        - containerPort: 8000\n        envFrom:\n        - secretRef:\n            name: rbtl-graphrag-secrets\n</code></pre>"},{"location":"DOCKER_DEPLOYMENT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DOCKER_DEPLOYMENT/#backend-wont-start","title":"Backend won't start","text":"<ul> <li>Check environment variables are set correctly</li> <li>Verify Neo4j connection: <code>docker-compose logs backend</code></li> <li>Check health endpoint: <code>curl http://localhost:8000/api/health</code></li> </ul>"},{"location":"DOCKER_DEPLOYMENT/#frontend-cant-connect-to-backend","title":"Frontend can't connect to backend","text":"<ul> <li>Verify <code>NEXT_PUBLIC_API_URL</code> is set correctly</li> <li>Check CORS settings in backend</li> <li>Ensure backend container is running: <code>docker-compose ps</code></li> </ul>"},{"location":"DOCKER_DEPLOYMENT/#build-fails","title":"Build fails","text":"<ul> <li>Clear Docker cache: <code>docker-compose build --no-cache</code></li> <li>Check Dockerfile paths are correct</li> <li>Verify all required files exist</li> </ul>"},{"location":"DOCKER_DEPLOYMENT/#development-vs-production-docker-modes","title":"Development vs Production Docker Modes","text":"<p>Important Clarification: Both \"Development Docker mode\" and \"Production Docker mode\" can run locally on your machine or on remote servers. The difference is about how the code runs, not where it runs:</p> <ul> <li>Production Docker mode = Optimized for deployment (code baked into image, no hot-reload, smaller/faster)</li> <li>Development Docker mode = Optimized for active coding (hot-reload, volume mounts, easier debugging)</li> </ul>"},{"location":"DOCKER_DEPLOYMENT/#development-docker-mode-with-hot-reload","title":"Development Docker Mode (with Hot Reload)","text":"<p>For active development with automatic code reloading:</p> <pre><code># Set ENVIRONMENT=development in .env file first\n# Then start with development overrides (hot-reload enabled)\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up --build\n</code></pre> <p>Features: - \u2705 Backend auto-reloads on Python file changes (via <code>--reload</code> flag) - \u2705 Frontend hot-reloads on React/TypeScript changes - \u2705 Source code mounted as volumes (no rebuild needed for code changes) - \u2705 Code changes reflect immediately without restarting containers - \u26a0\ufe0f Still need to rebuild if you change <code>requirements.txt</code> or <code>package.json</code> - \u26a0\ufe0f Larger container size (includes dev dependencies) - \u26a0\ufe0f Slower startup (runs dev servers)</p> <p>When to use: - Active coding and debugging - Testing code changes quickly - Local development (but can also run on remote servers)</p> <p>Environment Configuration: Make sure your <code>.env</code> file has: </p><pre><code>ENVIRONMENT=development\nNEO4J_URI_DEV=bolt://host.docker.internal:7687\nNEO4J_USER_DEV=neo4j\nNEO4J_PASSWORD_DEV=local-password\nNEO4J_DATABASE_DEV=neo4j\nMONGODB_URI_DEV=mongodb://airflow:tiktok@host.docker.internal:27017\nMONGODB_DB_DEV=social_media\nLANGFUSE_HOST_DEV=http://host.docker.internal:3000\n# ... other _DEV variables\n</code></pre><p></p>"},{"location":"DOCKER_DEPLOYMENT/#production-docker-mode","title":"Production Docker Mode","text":"<p>For optimized, production-ready containers:</p> <pre><code># Set ENVIRONMENT=production in .env file (or omit it)\n# Then start standard production build\ndocker-compose up --build\n</code></pre> <p>Features: - \u2705 Code baked into image (no volume mounts) - \u2705 Optimized builds (smaller images, faster startup) - \u2705 Production-ready configuration - \u2705 No dev dependencies in final image - \u26a0\ufe0f Code changes require rebuild (no hot-reload) - \u26a0\ufe0f Must rebuild image to see code changes</p> <p>When to use: - Production deployments - Testing production-like environment locally - CI/CD pipelines - When you want optimized, stable containers</p> <p>Environment Configuration: Make sure your <code>.env</code> file has: </p><pre><code>ENVIRONMENT=production  # or omit this line\nNEO4J_URI=bolt+s://prod-db.databases.neo4j.io\nNEO4J_USER=neo4j\nNEO4J_PASSWORD=your-password\nNEO4J_DATABASE=neo4j\nMONGODB_URI=mongodb+srv://prod-cluster...\nMONGODB_DB=rbl\n# ... production variables\n</code></pre><p></p> <p>Summary: - Both modes can run locally or on remote servers - Development mode = easier coding (hot-reload) - Production mode = optimized deployment (no hot-reload, smaller images) - The <code>ENVIRONMENT</code> variable (development/production) is separate and controls which databases to use</p>"},{"location":"DOCKER_DEPLOYMENT/#production-best-practices","title":"Production Best Practices","text":"<ul> <li>Use multi-stage builds (already configured)</li> <li>Set <code>NODE_ENV=production</code></li> <li>Use production-ready base images</li> <li>Configure proper health checks</li> <li>Set up logging and monitoring</li> </ul>"},{"location":"DOCKER_DEPLOYMENT/#image-sizes","title":"Image Sizes","text":"<p>Expected image sizes: - Backend: ~500-800 MB - Frontend: ~200-400 MB</p> <p>To reduce size: - Use <code>.dockerignore</code> (already configured) - Multi-stage builds (already configured) - Alpine base images (frontend uses alpine)</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting Started","text":"<p>Follow this guide to run GraphRAG locally with Neo4j, Langfuse, and the optional MongoDB-based knowledge base. The steps mirror the root <code>README.md</code> so that the canonical instructions live inside the docs site.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Node.js 18+ (for the Next.js frontend)</li> <li>Docker (for Langfuse stack)</li> <li>Access to a Neo4j Aura instance or self-hosted database</li> <li>OpenAI API key (or compatible LLM provider)</li> </ul>"},{"location":"getting-started/#1-clone-bootstrap","title":"1. Clone &amp; Bootstrap","text":"<pre><code>git clone https://github.com/bojansimoski/rbtl_graphrag.git\ncd rbtl_graphrag\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#2-configure-environment","title":"2. Configure Environment","text":"<p>Create <code>.env</code> in the project root. Use the template below and adjust credentials as needed:</p> <pre><code># Environment Selection\nENVIRONMENT=production  # Set to \"development\" for local development\n\n# Neo4j (Production)\nNEO4J_URI=neo4j+s://your-db.databases.neo4j.io\nNEO4J_USER=neo4j\nNEO4J_PASSWORD=***\n\n# Neo4j (Development - Optional)\n# Uncomment and set when ENVIRONMENT=development\n# NEO4J_URI_DEV=neo4j://127.0.0.1:7687\n# NEO4J_USER_DEV=neo4j\n# NEO4J_PASSWORD_DEV=local-password\n\n# Langfuse (Production)\nLANGFUSE_HOST=http://localhost:3001\nLANGFUSE_PUBLIC_KEY=pk-***\nLANGFUSE_SECRET_KEY=sk-***\n\n# Langfuse (Development - Optional)\n# Uncomment and set when ENVIRONMENT=development\n# LANGFUSE_HOST_DEV=http://localhost:3001\n# LANGFUSE_PUBLIC_KEY_DEV=pk-dev-***\n# LANGFUSE_SECRET_KEY_DEV=sk-dev-***\n\n# MongoDB (Production)\nMONGODB_URI=mongodb+srv://...\nMONGODB_DATABASE=graphrag\n\n# MongoDB (Development - Optional)\n# Uncomment and set when ENVIRONMENT=development\n# MONGODB_URI_DEV=mongodb://localhost:27017\n# MONGODB_DATABASE_DEV=social_media\n\n# OpenAI\nOPENAI_API_KEY=sk-***\nOPENAI_MODEL=gpt-4o\n\n# Optional\nENABLE_ANALYTICS_AGENT=false\nPROMPT_LABEL=production\n</code></pre>"},{"location":"getting-started/#environment-switching","title":"Environment Switching","text":"<p>The application supports switching between development and production environments:</p> <ul> <li>Production (default): Uses standard variables (<code>NEO4J_URI</code>, <code>MONGODB_URI</code>, <code>LANGFUSE_HOST</code>, etc.)</li> <li>Development: Set <code>ENVIRONMENT=development</code> to use <code>_DEV</code> suffixed variables</li> </ul> <p>Benefits: - Use local databases (Neo4j, MongoDB) for development - Use local Langfuse instance for development - Keep production credentials separate - Fallback to production if <code>_DEV</code> variables are not set</p> <p>Example for local development: </p><pre><code>ENVIRONMENT=development\nNEO4J_URI_DEV=neo4j://127.0.0.1:7687\nMONGODB_URI_DEV=mongodb://localhost:27017\nMONGODB_DATABASE_DEV=social_media\nLANGFUSE_HOST_DEV=http://localhost:3001\n# Production variables remain for reference but won't be used\n</code></pre><p></p> <p>Switching Environments with Docker:</p> <p>When using Docker, you need to recreate containers after changing the <code>ENVIRONMENT</code> variable. See the Docker Deployment Guide for detailed step-by-step instructions on how to switch between environments and update Docker containers.</p> <p>See <code>README.md</code> for the full list of optional knobs (<code>OUTPUT_MODE</code>, <code>DEBUG_PROMPT</code>, etc.).</p>"},{"location":"getting-started/#3-launch-supporting-services","title":"3. Launch Supporting Services","text":"<pre><code>docker-compose -f docker-compose.langfuse.yml up -d\n</code></pre> <p>Wait ~30 seconds and verify:</p> <ul> <li>Langfuse UI: http://localhost:3001</li> <li>PostgreSQL: localhost:5433</li> <li>ClickHouse: localhost:8123</li> </ul> <p>Use <code>docker-compose ... logs -f</code> for troubleshooting.</p>"},{"location":"getting-started/#4-smoke-tests","title":"4. Smoke Tests","text":"<pre><code># Dry-run Cypher generation\npython ai/text_to_cypher.py \"Return 5 Person nodes\"\n\n# Execute against Neo4j and return JSON\nEXECUTE_CYPHER=true OUTPUT_MODE=json python ai/text_to_cypher.py \"Return 5 Person nodes\"\n\n# Include conversational summary\nEXECUTE_CYPHER=true OUTPUT_MODE=chat python ai/text_to_cypher.py \"Return 5 Person nodes\"\n</code></pre> <p>Additional scripts (<code>ai/fewshots/generate_examples.py</code>, <code>ai/fewshots/generate_query_categories.py</code>) provide curated prompt data; run <code>DEBUG_PROMPT=true ...</code> to inspect the rendered templates.</p>"},{"location":"getting-started/#5-run-the-app","title":"5. Run the App","text":""},{"location":"getting-started/#recommended-docker-production-ready","title":"Recommended: Docker (Production-Ready)","text":"<p>The application is fully dockerized. Use Docker for consistent, production-like environments:</p> <pre><code># Production mode (optimized build, no hot-reload)\ndocker-compose up --build\n\n# Development mode (with hot-reload for active coding)\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up --build\n</code></pre> <p>Access the application: - Frontend: http://localhost:3003 - Backend API: http://localhost:8001 - API Docs: http://localhost:8001/docs</p> <p>Benefits: - \u2705 Consistent environment across local, staging, and production - \u2705 No need to manage Python/Node versions locally - \u2705 Matches cloud deployment exactly - \u2705 Easy to share with team members</p> <p>See Docker Deployment Guide for detailed instructions and troubleshooting.</p>"},{"location":"getting-started/#alternative-local-development-for-active-coding","title":"Alternative: Local Development (For Active Coding)","text":"<p>If you prefer running services directly (useful for debugging):</p> <p>Backend (FastAPI): </p><pre><code>source venv/bin/activate\nuvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000\n</code></pre><p></p> <p>Frontend (Next.js): </p><pre><code>cd frontend\nnpm install\nnpm run dev\n</code></pre><p></p> <p>With both servers running, open http://localhost:3002 to try the conversational interface.</p> <p>Note: Local development uses different ports (8000 for backend, 3002 for frontend) to avoid conflicts with Docker.</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Enable the experimental analytics agent by setting <code>ENABLE_ANALYTICS_AGENT=true</code> once you have the Neo4j GDS Agent running.</li> <li>Review the Architecture Overview to understand how each service fits together.</li> <li>Dive into the Testing Strategy before making code changes.</li> </ul>"},{"location":"architecture/ai-stack/","title":"AI & MCP Stack","text":""},{"location":"architecture/ai-stack/#ai-mcp-stack","title":"AI &amp; MCP Stack","text":"<p>Everything under <code>ai/</code> powers the LLM workflows, few-shot data, terminology normalization, and Model Context Protocol integrations.</p>"},{"location":"architecture/ai-stack/#text-to-cypher-pipeline","title":"Text-to-Cypher Pipeline","text":"<ul> <li>Entry point: <code>ai/text_to_cypher.py</code></li> <li>Inputs: user question, optional flags (<code>EXECUTE_CYPHER</code>, <code>OUTPUT_MODE</code>, <code>DEBUG_PROMPT</code>)</li> <li>Steps:</li> <li>Load schema context from <code>ai/schema/</code>.</li> <li>Render prompt templates from <code>ai/prompts/*.yaml</code>.</li> <li>Inject few-shot examples from <code>ai/fewshots/</code>.</li> <li>Send request to OpenAI (or override via env var).</li> <li>Optionally execute the generated query via Neo4j driver and summarize results.</li> </ul>"},{"location":"architecture/ai-stack/#terminology-management","title":"Terminology Management","text":"<ul> <li><code>ai/terminology/loader.py</code> ingests YAML definitions (e.g., <code>v1.yaml</code>) to enrich prompts with domain language and synonyms.</li> <li>Future work: automate exports into <code>docs/reference/glossary.md</code>.</li> </ul>"},{"location":"architecture/ai-stack/#mcp-client-integration","title":"MCP Client Integration","text":"<ul> <li><code>ai/mcp_client.py</code> provides async helpers to connect to MCP servers (notably the Neo4j GDS Agent).</li> <li>Supports interactive mode (<code>--interactive</code>) for manual tool testing.</li> <li>Shares credentials with the backend through common environment variables.</li> <li>See MCP Architecture for the full stdio/JSON-RPC handshake sequence.</li> </ul>"},{"location":"architecture/ai-stack/#analytics-agent-optional","title":"Analytics Agent (Optional)","text":"<ul> <li>Implemented in <code>ai/agent/graph_analytics_agent.py</code>.</li> <li>Routes qualifying questions to graph algorithms (<code>leiden</code>, <code>article_rank</code>, <code>bridges</code>, <code>count_nodes</code>).</li> <li>Controlled via <code>ENABLE_ANALYTICS_AGENT</code>. When disabled, all traffic goes through text-to-Cypher.</li> <li>See Graph Analytics Guide for configuration tips.</li> </ul>"},{"location":"architecture/ai-stack/#observability","title":"Observability","text":"<ul> <li><code>ai/llmops/langfuse_client.py</code> encapsulates Langfuse tracing.</li> <li>Prompts are versioned/labeled in Langfuse; the backend selects a label via the <code>PROMPT_LABEL</code> env var.</li> </ul>"},{"location":"architecture/ai-stack/#roadmap","title":"Roadmap","text":"<ul> <li>Document prompt schemas and response contracts directly from YAML files.</li> <li>Add mkdocstrings support to auto-publish function/class docs.</li> <li>Provide scripts that regenerate documentation artifacts (schema visualizations, glossary).</li> </ul>"},{"location":"architecture/backend/","title":"Backend Services","text":""},{"location":"architecture/backend/#backend-services","title":"Backend Services","text":"<p>The FastAPI backend lives in <code>backend/app/</code> and exposes REST endpoints consumed by the Next.js frontend, Langfuse, and external tools.</p>"},{"location":"architecture/backend/#api-surface","title":"API Surface","text":"<ul> <li><code>api/chat.py</code> \u2013 orchestrates chat sessions, translates user messages into Cypher or analytics jobs via <code>services/graphrag.py</code>.</li> <li><code>api/graph_info.py</code> \u2013 returns schema/metadata generated by <code>ai/schema/</code> utilities.</li> <li><code>api/knowledge_base.py</code> \u2013 interfaces with MongoDB to fetch KB entries.</li> <li><code>api/health.py</code> \u2013 readiness/liveness checks for deployment probes.</li> </ul>"},{"location":"architecture/backend/#service-layer","title":"Service Layer","text":"<ul> <li><code>services/chat_sessions.py</code> \u2013 manages session state, caching, and fallback logic.</li> <li><code>services/mongodb.py</code> \u2013 connection helpers and CRUD for the knowledge base.</li> <li><code>services/neo4j_sync.py</code> &amp; <code>update_category_in_neo4j.py</code> \u2013 utilities for keeping graph schema/categories synchronized.</li> <li><code>services/migrate_to_mongodb.py</code> \u2013 migration workflow for KB documents.</li> </ul>"},{"location":"architecture/backend/#integration-points","title":"Integration Points","text":"<ul> <li>Langfuse: instrumentation via <code>ai/llmops/langfuse_client.py</code>.</li> <li>MCP / GDS Agent: invoked when analytics routing is enabled.</li> <li>Environment Flags: <code>ENABLE_ANALYTICS_AGENT</code>, <code>PROMPT_LABEL</code>, and other settings in <code>.env</code> govern backend behavior.</li> </ul>"},{"location":"architecture/backend/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Auto-generated API reference using <code>mkdocstrings</code> once added to the build.</li> <li>Scenario-based guides for each endpoint (e.g., streaming responses vs. batched).</li> </ul>"},{"location":"architecture/diagrams/","title":"Architecture Diagrams","text":""},{"location":"architecture/diagrams/#architecture-diagrams","title":"Architecture Diagrams","text":"<p>This document provides three complementary Mermaid diagrams that illustrate the GraphRAG system from different perspectives:</p> <ol> <li>User Journey Diagram - Shows the user experience flow and interactions</li> <li>Cloud Infrastructure Diagram - Shows deployment architecture and service relationships</li> <li>AI Implementation Diagram - Shows the AI/LLM processing pipeline and decision flows</li> </ol>"},{"location":"architecture/diagrams/#1-user-journey-diagram","title":"1. User Journey Diagram","text":"<p>This diagram illustrates the user's perspective: how they interact with the system, what they see, and the flow of their experience.</p> <pre><code>flowchart TD\n    Start([User Opens Application]) --&gt; Login[Login/Select Username]\n    Login --&gt; Dashboard[Main Dashboard]\n\n    Dashboard --&gt; AskQuestion[Ask Natural Language Question]\n    Dashboard --&gt; ViewKB[Browse Knowledge Base]\n    Dashboard --&gt; ViewFavorites[View Favorites]\n    Dashboard --&gt; ViewHistory[View Chat History]\n\n    AskQuestion --&gt; Processing[System Processing]\n    Processing --&gt; RouteDecision{Route Decision}\n\n    RouteDecision --&gt;|Analytics Question| AnalyticsRoute[Analytics Agent]\n    RouteDecision --&gt;|Standard Query| CypherRoute[Text-to-Cypher]\n\n    AnalyticsRoute --&gt; AnalyticsResult[Graph Algorithm Results]\n    CypherRoute --&gt; CypherGen[Generate Cypher Query]\n    CypherGen --&gt; ExecuteQuery[Execute on Neo4j]\n    ExecuteQuery --&gt; QueryResults[Raw Query Results]\n\n    AnalyticsResult --&gt; Summarize[Generate Summary]\n    QueryResults --&gt; Summarize\n\n    Summarize --&gt; DisplayResults[Display Results]\n    DisplayResults --&gt; ShowCypher[Show Generated Cypher]\n    DisplayResults --&gt; ShowTable[Show Results Table]\n    DisplayResults --&gt; ShowSummary[Show Natural Language Summary]\n    DisplayResults --&gt; ShowRoute[Show Route Type Badge]\n\n    ShowCypher --&gt; UserActions{User Actions}\n    ShowTable --&gt; UserActions\n    ShowSummary --&gt; UserActions\n    ShowRoute --&gt; UserActions\n\n    UserActions --&gt;|Save| SaveFavorite[Save to Favorites]\n    UserActions --&gt;|Ask Follow-up| AskQuestion\n    UserActions --&gt;|Browse KB| ViewKB\n    UserActions --&gt;|Delete| DeleteMessage[Delete Message]\n\n    SaveFavorite --&gt; Dashboard\n    DeleteMessage --&gt; Dashboard\n    ViewKB --&gt; KBDetail[View Category Details]\n    KBDetail --&gt; Dashboard\n    ViewFavorites --&gt; Dashboard\n    ViewHistory --&gt; Dashboard\n\n    style Start fill:#e1f5ff\n    style Dashboard fill:#fff4e1\n    style Processing fill:#ffe1f5\n    style RouteDecision fill:#e1ffe1\n    style DisplayResults fill:#f0e1ff\n</code></pre>"},{"location":"architecture/diagrams/#2-cloud-infrastructure-diagram","title":"2. Cloud Infrastructure Diagram","text":"<p>This diagram shows the deployment architecture, cloud services, and how components communicate in a production environment.</p> <pre><code>graph TB\n    subgraph \"User Layer\"\n        Browser[Web Browser]\n        Mobile[Mobile App]\n    end\n\n    subgraph \"Azure Static Web Apps / CDN\"\n        Frontend[Next.js Frontend&lt;br/&gt;Port 3003]\n    end\n\n    subgraph \"Azure Container Apps\"\n        Backend[FastAPI Backend&lt;br/&gt;Port 8001]\n    end\n\n    subgraph \"Managed Services\"\n        Neo4j[(Neo4j Aura&lt;br/&gt;Graph Database)]\n        MongoDB[(MongoDB Atlas&lt;br/&gt;Knowledge Base)]\n    end\n\n    subgraph \"AI Services\"\n        OpenAI[OpenAI API&lt;br/&gt;GPT-4o]\n    end\n\n    subgraph \"Observability Stack\"\n        Langfuse[Langfuse UI&lt;br/&gt;Port 3001]\n        Postgres[(PostgreSQL&lt;br/&gt;Port 5433)]\n        ClickHouse[(ClickHouse&lt;br/&gt;Port 8123)]\n    end\n\n    subgraph \"Optional Services\"\n        GDSAgent[Neo4j GDS Agent&lt;br/&gt;via MCP stdio]\n    end\n\n    Browser --&gt;|HTTPS| Frontend\n    Mobile --&gt;|HTTPS| Frontend\n\n    Frontend --&gt;|REST API&lt;br/&gt;WebSocket| Backend\n\n    Backend --&gt;|Cypher Queries&lt;br/&gt;Bolt Protocol| Neo4j\n    Backend --&gt;|MongoDB Driver| MongoDB\n    Backend --&gt;|Langfuse SDK| Langfuse\n    Backend --&gt;|OpenAI SDK| OpenAI\n    Backend --&gt;|MCP stdio&lt;br/&gt;JSON-RPC| GDSAgent\n\n    Langfuse --&gt; Postgres\n    Langfuse --&gt; ClickHouse\n\n    GDSAgent -.-&gt;|Queries| Neo4j\n\n    Backend -.-&gt;|Traces| Langfuse\n\n    style Browser fill:#e1f5ff\n    style Frontend fill:#fff4e1\n    style Backend fill:#ffe1f5\n    style Neo4j fill:#e1ffe1\n    style MongoDB fill:#e1ffe1\n    style OpenAI fill:#f0e1ff\n    style Langfuse fill:#ffe1f5\n    style GDSAgent fill:#e1f5ff,stroke-dasharray: 5 5\n</code></pre>"},{"location":"architecture/diagrams/#3-ai-implementation-diagram","title":"3. AI Implementation Diagram","text":"<p>This diagram details the AI processing pipeline, showing how natural language questions are transformed into Cypher queries or routed to analytics tools, including all the AI components and decision points.</p> <pre><code>flowchart TD\n    Start([User Question]) --&gt; LoadContext[Load Context]\n\n    LoadContext --&gt; LoadSchema[Load Neo4j Schema&lt;br/&gt;ai/schema/]\n    LoadContext --&gt; LoadTerminology[Load Terminology&lt;br/&gt;ai/terminology/]\n    LoadContext --&gt; LoadPrompt[Load Prompt Template&lt;br/&gt;ai/prompts/]\n\n    LoadSchema --&gt; CheckAnalytics{Analytics&lt;br/&gt;Enabled?}\n    LoadTerminology --&gt; CheckAnalytics\n    LoadPrompt --&gt; CheckAnalytics\n\n    CheckAnalytics --&gt;|Yes| TryAnalytics[Analytics Agent Route]\n    CheckAnalytics --&gt;|No| TextToCypher[Text-to-Cypher Route]\n\n    subgraph \"Analytics Agent Path\"\n        TryAnalytics --&gt; LLMSelect[LLM Tool Selector&lt;br/&gt;GraphAnalyticsAgent]\n        LLMSelect --&gt; ToolDecision{Tool&lt;br/&gt;Appropriate?}\n        ToolDecision --&gt;|Yes| CallMCP[Call MCP Tool&lt;br/&gt;leiden/article_rank/bridges]\n        ToolDecision --&gt;|No| FallbackCypher[Fallback to Cypher]\n        CallMCP --&gt; MCPResult[MCP Tool Result]\n        MCPResult --&gt; AnalyticsSummary[Generate Summary&lt;br/&gt;LLM]\n        AnalyticsSummary --&gt; AnalyticsOutput[Return Analytics Result]\n    end\n\n    subgraph \"Text-to-Cypher Path\"\n        TextToCypher --&gt; VectorSearch{Vector Search&lt;br/&gt;Enabled?}\n        FallbackCypher --&gt; VectorSearch\n\n        VectorSearch --&gt;|Yes| SearchExamples[Search Similar Examples&lt;br/&gt;ai/fewshots/vector_store]\n        VectorSearch --&gt;|No| LoadStatic[Load Static Examples&lt;br/&gt;ai/fewshots/loader]\n\n        SearchExamples --&gt; RenderPrompt[Render Prompt Template]\n        LoadStatic --&gt; RenderPrompt\n\n        RenderPrompt --&gt; InjectSchema[Inject Schema Context]\n        RenderPrompt --&gt; InjectTerminology[Inject Terminology]\n        RenderPrompt --&gt; InjectExamples[Inject Few-Shot Examples]\n        RenderPrompt --&gt; InjectQuestion[Inject User Question]\n\n        InjectSchema --&gt; CompilePrompt[Compile Full Prompt]\n        InjectTerminology --&gt; CompilePrompt\n        InjectExamples --&gt; CompilePrompt\n        InjectQuestion --&gt; CompilePrompt\n\n        CompilePrompt --&gt; CallLLM[Call OpenAI LLM&lt;br/&gt;GPT-4o]\n        CallLLM --&gt; TraceLangfuse[Trace to Langfuse]\n        TraceLangfuse --&gt; ExtractCypher[Extract Cypher Query]\n\n        ExtractCypher --&gt; ValidateCypher{Valid&lt;br/&gt;Cypher?}\n        ValidateCypher --&gt;|No| Error[Return Error]\n        ValidateCypher --&gt;|Yes| ExecuteCypher[Execute on Neo4j]\n\n        ExecuteCypher --&gt; QueryResults[Raw Query Results]\n        QueryResults --&gt; LoadSummaryPrompt[Load Summary Prompt&lt;br/&gt;graph-result-summarizer]\n        LoadSummaryPrompt --&gt; RenderSummary[Render Summary Prompt]\n        RenderSummary --&gt; CallSummaryLLM[Call OpenAI LLM&lt;br/&gt;for Summary]\n        CallSummaryLLM --&gt; TraceSummary[Trace Summary to Langfuse]\n        TraceSummary --&gt; CypherOutput[Return Cypher Result]\n    end\n\n    AnalyticsOutput --&gt; End([Return to User])\n    CypherOutput --&gt; End\n    Error --&gt; End\n\n    style Start fill:#e1f5ff\n    style CheckAnalytics fill:#fff4e1\n    style TryAnalytics fill:#ffe1f5\n    style TextToCypher fill:#ffe1f5\n    style CallLLM fill:#f0e1ff\n    style CallSummaryLLM fill:#f0e1ff\n    style LLMSelect fill:#f0e1ff\n    style End fill:#e1ffe1\n</code></pre>"},{"location":"architecture/diagrams/#diagram-usage-recommendations","title":"Diagram Usage Recommendations","text":""},{"location":"architecture/diagrams/#when-to-use-each-diagram","title":"When to Use Each Diagram","text":"<ol> <li>User Journey Diagram: </li> <li>Best for onboarding new users</li> <li>Demonstrating the user experience to stakeholders</li> <li>UX/UI design discussions</li> <li> <p>User documentation</p> </li> <li> <p>Cloud Infrastructure Diagram:</p> </li> <li>DevOps and deployment planning</li> <li>Infrastructure reviews</li> <li>Cost estimation discussions</li> <li>Security and compliance audits</li> <li> <p>System architecture documentation</p> </li> <li> <p>AI Implementation Diagram:</p> </li> <li>Developer onboarding</li> <li>AI/ML team discussions</li> <li>Debugging AI pipeline issues</li> <li>Prompt engineering sessions</li> <li>Performance optimization</li> </ol>"},{"location":"architecture/diagrams/#integration-with-documentation","title":"Integration with Documentation","text":"<p>These diagrams complement the existing architecture documentation:</p> <ul> <li>User Journey \u2192 See <code>frontend.md</code> for component details</li> <li>Cloud Infrastructure \u2192 See <code>azure-deployment.md</code> for deployment specifics</li> <li>AI Implementation \u2192 See <code>ai-stack.md</code> and <code>mcp.md</code> for technical details</li> </ul>"},{"location":"architecture/diagrams/#maintenance","title":"Maintenance","text":"<ul> <li>Update diagrams when adding new user features (User Journey)</li> <li>Update diagrams when changing deployment architecture (Cloud Infrastructure)</li> <li>Update diagrams when modifying AI pipeline or adding new LLM routes (AI Implementation)</li> </ul>"},{"location":"architecture/diagrams/#exporting-diagrams","title":"Exporting Diagrams","text":"<p>To export these diagrams as images:</p> <ol> <li>Use Mermaid Live Editor: https://mermaid.live/</li> <li>Copy each diagram code block</li> <li>Export as PNG/SVG</li> <li>Add to documentation or presentations</li> </ol> <p>Alternatively, if using MkDocs with mermaid plugin, these will render automatically in the documentation site.</p>"},{"location":"architecture/frontend/","title":"Frontend / UI","text":""},{"location":"architecture/frontend/#frontend-ui","title":"Frontend / UI","text":"<p>The chat experience lives in the <code>frontend/</code> Next.js app. This page carries over the details from <code>FRONTEND_ARCHITECTURE.md</code>, focusing on structure, Azure-ready deployment, and integration patterns.</p>"},{"location":"architecture/frontend/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>User \u2194 Next.js (Azure Static Web Apps / Vercel)\n            \u2195 REST + WebSockets/SSE\n         FastAPI backend (Azure Container Apps)\n            \u2195\n      Neo4j Aura \u00b7 Langfuse \u00b7 MongoDB\n</code></pre> <p>The frontend fetches REST APIs and (optionally) streams updates over WebSockets/SSE. Hosting options include Azure Static Web Apps or any static host/CDN.</p>"},{"location":"architecture/frontend/#project-layout","title":"Project Layout","text":"<ul> <li><code>app/layout.tsx</code>, <code>app/page.tsx</code> \u2013 App Router entry points with chat shell.</li> <li><code>components/</code></li> <li>Conversation: <code>ChatInterface</code>, <code>MessageList</code>, <code>MessageInput</code>.</li> <li>Insights: <code>GraphInfo</code>, <code>CypherViewer</code>, <code>ResultsTable</code>.</li> <li>Knowledge base: <code>CategoryForm</code>, <code>CategoryDetail</code>, <code>FavoritesView</code>, <code>Sidebar</code>.</li> <li><code>lib/api.ts</code>, <code>lib/knowledgeBaseApi.ts</code> \u2013 typed fetch helpers.</li> <li><code>globals.css</code>, <code>tailwind.config.js</code> \u2013 design system built on Tailwind CSS; shadcn/ui or similar component primitives can be layered on.</li> <li><code>public/</code> \u2013 static assets, icons, diagram exports.</li> </ul> <p>State management uses React context with optional libraries like Zustand for chat history persistence. Real-time behavior can leverage browser Fetch streaming, Server-Sent Events, or WebSockets exposed by the backend.</p>"},{"location":"architecture/frontend/#developer-workflow","title":"Developer Workflow","text":"<pre><code>cd frontend\nnpm install\nnpm run dev\n</code></pre> <p>Add <code>frontend/.env.local</code> containing <code>NEXT_PUBLIC_API_URL=http://localhost:8000</code>. When deploying, swap in the production FastAPI URL and any telemetry keys.</p>"},{"location":"architecture/frontend/#azure-deployment-notes","title":"Azure Deployment Notes","text":"<ul> <li>Hosting: Azure Static Web Apps fronts the compiled Next.js site; alternatively host on Azure App Service, Vercel, or Netlify.</li> <li>Backend connectivity: Use Azure Container Apps or App Service for FastAPI. Configure CORS to allow the frontend origin.</li> <li>Secrets: Keep API URLs, Langfuse keys, and feature flags in Azure Key Vault, surfaced as Static Web Apps secrets.</li> <li>Monitoring: Pair Application Insights (frontend + backend) with Langfuse for LLM traces.</li> </ul>"},{"location":"architecture/frontend/#feature-checklist","title":"Feature Checklist","text":"<ul> <li>Streaming responses with typing indicators.</li> <li>Cypher visualization (syntax highlight, copy-to-clipboard).</li> <li>Tabular or charted results via <code>ResultsTable</code>.</li> <li>Error and retry states surfaced inline.</li> <li>Knowledge-base workflows (favorites, category curation).</li> <li>Progress cards describing whether the analytics agent or standard Cypher path handled the question.</li> </ul> <p>Future documentation will include component prop tables, accessibility audit steps, and an end-to-end data-flow diagram linking React hooks to backend services.</p>"},{"location":"architecture/mcp/","title":"MCP Architecture","text":""},{"location":"architecture/mcp/#mcp-architecture","title":"MCP Architecture","text":"<p>This page distills <code>MCP_ARCHITECTURE.md</code> into a concise explanation of how GraphRAG talks to external tools such as the Neo4j GDS Agent.</p>"},{"location":"architecture/mcp/#what-is-mcp","title":"What Is MCP?","text":"<p>Model Context Protocol (MCP) standardizes how AI assistants (clients) interact with tool servers. Messages travel over JSON-RPC, typically via stdio pipes, which keeps the integration portable and secure.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    JSON-RPC / stdio    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 MCP Client   \u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt; \u2502 MCP Server   \u2502\n\u2502 (our code)   \u2502                        \u2502 (gds-agent)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                                         \u2502\n        \u25bc                                         \u25bc\n  Python services                           Neo4j + GDS\n</code></pre>"},{"location":"architecture/mcp/#client-lifecycle","title":"Client Lifecycle","text":"<ol> <li>Setup \u2013 <code>Neo4jGDSAgentClient</code> (in <code>ai/mcp_client.py</code>) loads Neo4j credentials, locates the <code>uvx gds-agent</code> command, and prepares environment variables.</li> <li>Connect \u2013 <code>stdio_client()</code> launches the server as a subprocess, wiring stdout/stdin to async memory streams managed by AnyIO.</li> <li>Initialize \u2013 <code>ClientSession.initialize()</code> performs the MCP handshake (server sends <code>initialize</code>, client responds, both sides exchange capabilities).</li> <li>List Tools \u2013 <code>session.list_tools()</code> requests metadata (name, description, JSON schema inputs) for algorithms like <code>article_rank</code>, <code>leiden</code>, etc.</li> <li>Call Tool \u2013 <code>session.call_tool()</code> sends parameters, waits for results, and returns textual or structured content to the caller.</li> <li>Close \u2013 Streams are closed and the subprocess exits cleanly.</li> </ol> <p>If the server fails to send its initialization payload, the client will hang while waiting for the handshake\u2014this explains earlier connectivity issues filed against <code>gds-agent</code>.</p>"},{"location":"architecture/mcp/#message-flow","title":"Message Flow","text":"<pre><code>Client                        Server\n  \u2502   launch subprocess   \u2500\u2500\u2500\u25b6 \u2502\n  \u2502                           \u2502 start process\n  \u2502  wait initialize      \u25c0\u2500\u2500\u2500\u2502 send initialize request\n  \u2502  send init response   \u2500\u2500\u2500\u25b6\u2502\n  \u2502  tools/list           \u2500\u2500\u2500\u25b6\u2502 enumerate algorithms\n  \u2502                      \u25c0\u2500\u2500\u2500 \u2502 respond with tool metadata\n  \u2502  tools/call           \u2500\u2500\u2500\u25b6\u2502 execute algorithm / query Neo4j\n  \u2502                      \u25c0\u2500\u2500\u2500 \u2502 return result content\n</code></pre>"},{"location":"architecture/mcp/#why-stdio","title":"Why stdio?","text":"<ul> <li>No open ports or network ACLs required.</li> <li>Works across macOS/Linux/Windows without extra services.</li> <li>Easier local debugging\u2014just inspect stdout/stderr streams.</li> </ul>"},{"location":"architecture/mcp/#debugging-tips","title":"Debugging Tips","text":"<ul> <li>Run <code>python ai/mcp_client.py --interactive</code> to step through connection, list tools, and invoke them manually.</li> <li>Use <code>DEBUG=1</code> (AnyIO capability) or <code>LANGFUSE</code> traces to capture MCP request/response payloads.</li> <li>If initialization stalls, confirm the gds-agent version and verify it supports standalone stdio clients (some builds originally targeted Claude Desktop only).</li> </ul> <p>The GraphRAG backend reuses this client to power the analytics agent described in the guides section.</p>"},{"location":"architecture/system-overview/","title":"Overview","text":""},{"location":"architecture/system-overview/#system-overview","title":"System Overview","text":"<p>GraphRAG spans four major subsystems:</p> <ol> <li>User Experience \u2013 Next.js app (see <code>frontend/</code>) that manages chat flows, query results, and knowledge base navigation.</li> <li>Application Layer \u2013 FastAPI backend (<code>backend/app</code>) that orchestrates conversations, routes graph operations, and exposes REST APIs.</li> <li>Graph &amp; Knowledge Stores \u2013 Neo4j for graph data, MongoDB for knowledge base content, plus optional Langfuse PostgreSQL/ClickHouse stack for observability.</li> <li>AI &amp; Automation \u2013 Prompt pipelines, MCP integrations, and graph analytics agents housed under <code>ai/</code>.</li> </ol> <pre><code>flowchart LR\n    User(UI) --&gt;|HTTPS| Frontend\n    Frontend --&gt;|REST/WebSocket| Backend\n    Backend --&gt;|Cypher| Neo4j[(Neo4j)]\n    Backend --&gt;|Mongo driver| Mongo[(MongoDB)]\n    Backend --&gt;|Langfuse SDK| Langfuse[(Langfuse)]\n    Backend --&gt;|MCP| GDS[(Neo4j GDS Agent)]\n    Backend --&gt;|LLM APIs| OpenAI[(OpenAI)]\n</code></pre>"},{"location":"architecture/system-overview/#key-responsibilities","title":"Key Responsibilities","text":"<ul> <li>Frontend: Collects user input, streams backend responses, visualizes Cypher results, and surfaces progress/status cards for analytics routing.</li> <li>Backend: Hosts chat endpoints (<code>backend/app/api/chat.py</code>), exposes graph metadata (<code>graph_info.py</code>), and coordinates agent routing via <code>backend/app/services/graphrag.py</code>.</li> <li>AI Layer: Generates prompts (YAML files in <code>ai/prompts/</code>), manages few-shot examples (<code>ai/fewshots/</code>), and facilitates MCP sessions (<code>ai/mcp_client.py</code>).</li> <li>Observability: Langfuse traces capture LLM calls, prompt versions, and tool invocations; logs integrate with whichever platform you deploy.</li> </ul>"},{"location":"architecture/system-overview/#deployment-targets","title":"Deployment Targets","text":"<ul> <li>Local Dev: Fully dockerized with <code>docker-compose.yml</code> (production mode) or <code>docker-compose.dev.yml</code> (hot-reload). Langfuse runs via <code>docker-compose.langfuse.yml</code>. Alternative: run services directly (Uvicorn + Next.js dev server) for active debugging.</li> <li>Staging/Prod: Docker containers deployed to Azure Container Apps. Backend and frontend are separate containers built from <code>backend/Dockerfile</code> and <code>frontend/Dockerfile</code>. Neo4j (Aura) and MongoDB (Atlas/Cosmos DB) are managed services. GitHub Actions automates Docker build and deployment.</li> </ul> <p>See Getting Started for local Docker setup and Azure Production Deployment for cloud deployment.</p> <p>See the dedicated pages for deep dives into each subsystem.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>We welcome feature ideas, bug fixes, and documentation improvements. This section will evolve into the canonical contributor experience.</p>"},{"location":"contributing/#workflow","title":"Workflow","text":"<ol> <li>Create an issue (or pick one with the <code>help wanted</code> label).</li> <li>Branch from <code>main</code> using <code>feat/</code>, <code>fix/</code>, or <code>docs/</code> prefixes.</li> <li>Run backend + frontend tests plus <code>mkdocs build --strict</code> before opening a PR.</li> <li>Include screenshots or Langfuse trace links when changing UI or prompts.</li> <li>Tag relevant reviewers (backend, frontend, AI, docs).</li> </ol>"},{"location":"contributing/#style-notes","title":"Style Notes","text":"<ul> <li>Python: follow Ruff/Black defaults (to be enforced in CI).</li> <li>TypeScript/React: stick with ESLint + Prettier defaults from <code>frontend/</code>.</li> <li>Docs: keep sentences short, use active voice, prefer tables/diagrams when clarity improves.</li> </ul>"},{"location":"contributing/#definition-of-done","title":"Definition of Done","text":"<ul> <li>Tests pass locally.</li> <li>Docs updated when behavior changes (use the appropriate page in <code>docs/</code>).</li> <li>Release notes entry added if the change is user visible (future <code>docs/changelog.md</code>).</li> </ul>"},{"location":"contributing/#roadmap-for-this-section","title":"Roadmap for This Section","text":"<ul> <li>Add PR template.</li> <li>Publish coding standards and branching strategy.</li> <li>Document mkdocs contribution guide (how to add new pages, how nav works).</li> </ul>"},{"location":"guides/graph-analytics/","title":"Graph Analytics Agent Guide","text":""},{"location":"guides/graph-analytics/#graph-analytics-agent-guide","title":"Graph Analytics Agent Guide","text":"<p>Blend Graph Data Science algorithms into the regular GraphRAG chat workflow by enabling the Graph Analytics Agent. Content below distills the legacy <code>GRAPH_ANALYTICS_GUIDE.md</code>.</p>"},{"location":"guides/graph-analytics/#overview","title":"Overview","text":"<p>The agent extends text-to-Cypher with analytics such as community detection, influence ranking, and bridge analysis. Routing happens automatically based on user intent; when no analytics tool fits, the request falls back to standard Cypher generation.</p>"},{"location":"guides/graph-analytics/#enable-the-agent","title":"Enable the Agent","text":"<ol> <li>Install the Neo4j GDS Agent (<code>pip install gds-agent</code>) or run it as a remote MCP server.</li> <li>Populate <code>.env</code> with the same credentials the GDS Agent expects: <code>NEO4J_URI</code>, <code>NEO4J_USER</code>, <code>NEO4J_PASSWORD</code>, optional <code>NEO4J_DATABASE</code>.</li> <li>Set <code>ENABLE_ANALYTICS_AGENT=true</code> and restart the backend.</li> <li>Verify connectivity by running <code>python ai/mcp_client.py --interactive</code> and listing tools.</li> </ol>"},{"location":"guides/graph-analytics/#available-tools","title":"Available Tools","text":"Tool Purpose Example Prompts <code>article_rank</code> Ranks nodes by influence using ArticleRank \u201cWhich influencers are most important?\u201d, \u201cShow me the top creators by ArticleRank score.\u201d <code>leiden</code> Detects communities/clusters via the Leiden algorithm \u201cFind communities of people who follow similar influencers.\u201d <code>bridges</code> Surfaces critical edges whose removal disconnects the graph \u201cWhich connections are essential for linking neighborhoods?\u201d <code>count_nodes</code> Provides dataset size statistics \u201cHow many people, influencers, and areas are there?\u201d <p>Each capability lives in <code>ai/agent/graph_analytics_agent.py</code>. Inputs such as <code>nodeLabels</code>, <code>relTypes</code>, <code>nodeIdentifierProperty</code>, or algorithm-specific knobs (e.g., <code>minCommunitySize</code>) are inferred from natural language, but you can override them explicitly:</p> <pre><code>await analytics_agent.run(\n    \"Find person communities\",\n    tool_name=\"leiden\",\n    inputs={\"nodeLabels\": [\"Person\"], \"relTypes\": [\"FOLLOWS\"], \"minCommunitySize\": 10},\n)\n</code></pre>"},{"location":"guides/graph-analytics/#routing-logic","title":"Routing Logic","text":"<ol> <li>Chat API receives a user question.</li> <li>Intent classifier (LLM-based with keyword fallback) checks for analytics cues (communities, influence, bridges, graph size).</li> <li>If matched, the backend calls the MCP client, executes the tool, and summarizes the results.</li> <li>Frontend progress cards tell the user which route ran (analytics vs. text-to-Cypher).</li> </ol> <p>Regular Cypher queries still handle counts, aggregations, or lookups that do not require heavy analytics.</p>"},{"location":"guides/graph-analytics/#integration-points","title":"Integration Points","text":"<ul> <li>Backend \u2013 <code>backend/app/api/chat.py</code> wires routing through <code>services/graphrag.py</code>, which instantiates the agent once and reuses it per request.  </li> <li>Frontend \u2013 no UX changes required; messages flow through the same UI, but analytics-specific metadata is displayed to set expectations.</li> </ul>"},{"location":"guides/graph-analytics/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Tool not found: ensure the GDS Agent exposes it (<code>python ai/mcp_client.py --interactive --list-tools</code>).  </li> <li>Credentials rejected: confirm TLS-enabled URIs for Aura (<code>neo4j+s://...</code>).  </li> <li>Slow responses: monitor Langfuse traces when algorithms traverse large graphs; consider raising timeouts or narrowing parameters.  </li> <li>Fallback triggered: set <code>DEBUG_PROMPT=true</code> and inspect routing prompts/logs to understand why the LLM avoided analytics.</li> </ul>"},{"location":"guides/graph-analytics/#future-tools","title":"Future Tools","text":"<p>The agent reads MCP metadata to discover new tools automatically. To add one:</p> <ol> <li>Define a <code>ToolConfig</code> in <code>_build_default_configs()</code>.</li> <li>Implement a custom summary builder.</li> <li>Regenerate docs to capture the new capability.</li> </ol> <p>Potential additions include <code>shortest_path</code>, <code>betweenness_centrality</code>, <code>pagerank</code>, and <code>connected_components</code>.</p>"},{"location":"guides/prompts/","title":"Prompt &amp; Few-Shot Management","text":""},{"location":"guides/prompts/#prompt-few-shot-management","title":"Prompt &amp; Few-Shot Management","text":"<p>Prompt quality drives GraphRAG accuracy. This guide tracks where templates live and how to evolve them safely.</p>"},{"location":"guides/prompts/#file-layout","title":"File Layout","text":"<ul> <li><code>ai/prompts/*.yaml</code> \u2013 Langfuse-compatible templates (e.g., <code>text_to_cypher_v1.yaml</code>, <code>result_summarizer_v1.yaml</code>).</li> <li><code>ai/fewshots/</code> \u2013 scripts and JSON files for query categories and examples.</li> <li><code>ai/terminology/</code> \u2013 YAML dictionaries that enrich prompts with domain-specific terms.</li> </ul>"},{"location":"guides/prompts/#workflow","title":"Workflow","text":"<ol> <li>Draft Locally \u2013 edit the YAML template, keeping variables consistent with what backend services expect.</li> <li>Sync to Langfuse \u2013 use Langfuse UI or API to update the prompt, applying the same label as in <code>.env</code> (<code>PROMPT_LABEL</code> default <code>production</code>).</li> <li>Record Changes \u2013 document rationale and testing evidence in the PR description or future <code>docs/changelog.md</code>.</li> <li>Backfill Few-Shot Data \u2013 regenerate categories/examples via:</li> </ol> <pre><code>python ai/fewshots/generate_query_categories.py\npython ai/fewshots/generate_examples.py\n</code></pre> <ol> <li>Verify \u2013 run smoke tests (<code>DEBUG_PROMPT=true</code>) and capture Langfuse traces for reviewers.</li> </ol>"},{"location":"guides/prompts/#tips","title":"Tips","text":"<ul> <li>Use <code>response_format={\"type\": \"json_object\"}</code> when possible for structured outputs.</li> <li>Keep terminology JSON/YAML small and composable to avoid bloated prompts.</li> <li>When introducing new instructions, update the documentation page that references the behavior (e.g., analytics routing, summarization).</li> </ul>"},{"location":"guides/prompts/#backlog","title":"Backlog","text":"<ul> <li>Automate prompt diffing inside CI.</li> <li>Add linting for YAML placeholders.</li> <li>Mirror final Langfuse prompt text back into this repo for change tracking.</li> </ul>"},{"location":"operations/azure-deployment/","title":"Azure Production Deployment","text":""},{"location":"operations/azure-deployment/#azure-production-deployment-plan","title":"Azure Production Deployment Plan","text":"<p>This guide outlines the recommended Azure components and deployment steps for RBTL GraphRAG production deployment using Docker containers.</p>"},{"location":"operations/azure-deployment/#overview","title":"Overview","text":"<p>The application is deployed as two Docker containers on Azure Container Apps: - Backend: FastAPI application (from <code>backend/Dockerfile</code>) - Frontend: Next.js application (from <code>frontend/Dockerfile</code>)</p> <p>Both containers are built locally or via CI/CD, pushed to Azure Container Registry (ACR), and deployed to Azure Container Apps for auto-scaling and high availability.</p>"},{"location":"operations/azure-deployment/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Azure Cloud                              \u2502\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502  \u2502  Frontend        \u2502         \u2502  Backend API      \u2502            \u2502\n\u2502  \u2502  (Next.js)       \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502  (FastAPI)       \u2502            \u2502\n\u2502  \u2502                  \u2502  HTTPS  \u2502                   \u2502            \u2502\n\u2502  \u2502  Azure Static    \u2502  REST   \u2502  Azure Container \u2502            \u2502\n\u2502  \u2502  Web Apps        \u2502  +      \u2502  Apps             \u2502            \u2502\n\u2502  \u2502  (CDN)           \u2502  WS/SSE \u2502  (Auto-scaling)   \u2502            \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                                          \u2502                       \u2502\n\u2502                                          \u25bc                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502  \u2502         Azure Services                           \u2502           \u2502\n\u2502  \u2502  \u2022 Azure OpenAI (or OpenAI API)                \u2502           \u2502\n\u2502  \u2502  \u2022 Neo4j Aura (managed)                         \u2502           \u2502\n\u2502  \u2502  \u2022 Azure Cosmos DB (MongoDB API)                \u2502           \u2502\n\u2502  \u2502  \u2022 Azure Key Vault (secrets)                    \u2502           \u2502\n\u2502  \u2502  \u2022 Azure Application Insights (monitoring)       \u2502           \u2502\n\u2502  \u2502  \u2022 Azure Container Registry (ACR)               \u2502           \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"operations/azure-deployment/#recommended-azure-components","title":"Recommended Azure Components","text":"Component Service Purpose Frontend Hosting Azure Container Apps Run Next.js frontend Docker container with auto-scaling Backend Hosting Azure Container Apps Run FastAPI backend Docker container with auto-scaling Container Registry Azure Container Registry (ACR) Store and version Docker images Secrets Management Azure Key Vault Secure storage for API keys and credentials Database Azure Cosmos DB (MongoDB API) Knowledge base storage Monitoring Azure Application Insights Application performance and error tracking CI/CD GitHub Actions Automated Docker build and deployment pipeline"},{"location":"operations/azure-deployment/#external-services","title":"External Services","text":"<ul> <li>Neo4j Aura (managed Neo4j)</li> <li>OpenAI API (or Azure OpenAI)</li> <li>Langfuse (cloud or self-hosted)</li> </ul>"},{"location":"operations/azure-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Azure Subscription</li> <li>Azure CLI installed (<code>az login</code>)</li> <li>Docker installed locally</li> <li>GitHub repository access</li> </ul>"},{"location":"operations/azure-deployment/#deployment-phases","title":"Deployment Phases","text":""},{"location":"operations/azure-deployment/#phase-1-infrastructure-setup","title":"Phase 1: Infrastructure Setup","text":""},{"location":"operations/azure-deployment/#11-create-resource-group","title":"1.1 Create Resource Group","text":"<pre><code>az group create \\\n  --name rg-rbtl-graphrag-prod \\\n  --location westeurope\n</code></pre>"},{"location":"operations/azure-deployment/#12-create-azure-container-registry-acr","title":"1.2 Create Azure Container Registry (ACR)","text":"<pre><code>az acr create \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --name acrrbtlgraphrag \\\n  --sku Basic \\\n  --admin-enabled true\n</code></pre>"},{"location":"operations/azure-deployment/#13-create-azure-key-vault","title":"1.3 Create Azure Key Vault","text":"<pre><code>az keyvault create \\\n  --name kv-rbtl-graphrag-prod \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --location westeurope \\\n  --sku standard\n</code></pre>"},{"location":"operations/azure-deployment/#14-create-azure-container-apps-environment","title":"1.4 Create Azure Container Apps Environment","text":"<pre><code>az containerapp env create \\\n  --name env-rbtl-graphrag-prod \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --location westeurope\n</code></pre>"},{"location":"operations/azure-deployment/#15-frontend-container-app","title":"1.5 Frontend Container App","text":"<p>The frontend will be deployed as a Container App using the dockerized Next.js image. Both frontend and backend use the same Container Apps platform for consistency.</p>"},{"location":"operations/azure-deployment/#16-create-azure-cosmos-db-mongodb-api","title":"1.6 Create Azure Cosmos DB (MongoDB API)","text":"<pre><code>az cosmosdb create \\\n  --name cosmos-rbtl-graphrag-prod \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --kind MongoDB \\\n  --locations regionName=westeurope failoverPriority=0\n</code></pre>"},{"location":"operations/azure-deployment/#phase-2-secrets-configuration","title":"Phase 2: Secrets Configuration","text":""},{"location":"operations/azure-deployment/#21-store-secrets-in-key-vault","title":"2.1 Store Secrets in Key Vault","text":"<pre><code># Neo4j credentials\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"NEO4J-URI\" \\\n  --value \"neo4j+s://your-db-id.databases.neo4j.io\"\n\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"NEO4J-USER\" \\\n  --value \"neo4j\"\n\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"NEO4J-PASSWORD\" \\\n  --value \"your-secure-password\"\n\n# OpenAI\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"OPENAI-API-KEY\" \\\n  --value \"sk-proj-...\"\n\n# Langfuse\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"LANGFUSE-HOST\" \\\n  --value \"https://cloud.langfuse.com\"\n\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"LANGFUSE-PUBLIC-KEY\" \\\n  --value \"pk-lf-...\"\n\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"LANGFUSE-SECRET-KEY\" \\\n  --value \"sk-lf-...\"\n\n# MongoDB (Cosmos DB)\naz keyvault secret set \\\n  --vault-name kv-rbtl-graphrag-prod \\\n  --name \"MONGODB-URI\" \\\n  --value \"$(az cosmosdb keys list \\\n    --name cosmos-rbtl-graphrag-prod \\\n    --resource-group rg-rbtl-graphrag-prod \\\n    --type connection-strings \\\n    --query 'connectionStrings[0].connectionString' -o tsv)\"\n</code></pre>"},{"location":"operations/azure-deployment/#22-grant-container-apps-access-to-key-vault","title":"2.2 Grant Container Apps Access to Key Vault","text":"<pre><code># Get managed identity (will be created with container app)\n# Then grant access:\naz keyvault set-policy \\\n  --name kv-rbtl-graphrag-prod \\\n  --object-id &lt;container-app-identity-id&gt; \\\n  --secret-permissions get list\n</code></pre>"},{"location":"operations/azure-deployment/#phase-3-backend-docker-container-deployment","title":"Phase 3: Backend Docker Container Deployment","text":""},{"location":"operations/azure-deployment/#31-build-and-push-docker-image","title":"3.1 Build and Push Docker Image","text":"<p>The backend uses the <code>backend/Dockerfile</code> to create a production-ready container:</p> <pre><code># Login to ACR\naz acr login --name acrrbtlgraphrag\n\n# Build backend Docker image from backend/Dockerfile\ndocker build -f backend/Dockerfile -t acrrbtlgraphrag.azurecr.io/rbtl-graphrag-backend:latest .\n\n# Tag with commit SHA for versioning\ndocker tag acrrbtlgraphrag.azurecr.io/rbtl-graphrag-backend:latest \\\n  acrrbtlgraphrag.azurecr.io/rbtl-graphrag-backend:$(git rev-parse --short HEAD)\n\n# Push both tags to ACR\ndocker push acrrbtlgraphrag.azurecr.io/rbtl-graphrag-backend:latest\ndocker push acrrbtlgraphrag.azurecr.io/rbtl-graphrag-backend:$(git rev-parse --short HEAD)\n</code></pre> <p>What the Dockerfile does: - Uses Python 3.13-slim base image - Installs all dependencies from <code>backend/requirements.txt</code> - Copies application code (backend, ai, utils directories) - Exposes port 8000 - Runs FastAPI with uvicorn</p>"},{"location":"operations/azure-deployment/#32-create-container-app-for-backend","title":"3.2 Create Container App for Backend","text":"<pre><code>az containerapp create \\\n  --name ca-rbtl-graphrag-backend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --environment env-rbtl-graphrag-prod \\\n  --image acrrbtlgraphrag.azurecr.io/rbtl-graphrag-backend:latest \\\n  --target-port 8000 \\\n  --ingress external \\\n  --registry-server acrrbtlgraphrag.azurecr.io \\\n  --registry-username $(az acr credential show --name acrrbtlgraphrag --query username -o tsv) \\\n  --registry-password $(az acr credential show --name acrrbtlgraphrag --query passwords[0].value -o tsv) \\\n  --min-replicas 1 \\\n  --max-replicas 5 \\\n  --cpu 1.0 \\\n  --memory 2.0Gi \\\n  --env-vars \\\n    NEO4J_URI=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/NEO4J-URI/)\" \\\n    NEO4J_USER=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/NEO4J-USER/)\" \\\n    NEO4J_PASSWORD=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/NEO4J-PASSWORD/)\" \\\n    OPENAI_API_KEY=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/OPENAI-API-KEY/)\" \\\n    LANGFUSE_HOST=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/LANGFUSE-HOST/)\" \\\n    LANGFUSE_PUBLIC_KEY=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/LANGFUSE-PUBLIC-KEY/)\" \\\n    LANGFUSE_SECRET_KEY=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/LANGFUSE-SECRET-KEY/)\" \\\n    MONGODB_URI=\"@Microsoft.KeyVault(SecretUri=https://kv-rbtl-graphrag-prod.vault.azure.net/secrets/MONGODB-URI/)\" \\\n    MONGODB_DATABASE=graphrag \\\n    OPENAI_MODEL=gpt-4o \\\n    PROMPT_LABEL=production \\\n    ENABLE_ANALYTICS_AGENT=false\n</code></pre>"},{"location":"operations/azure-deployment/#33-get-backend-url","title":"3.3 Get Backend URL","text":"<pre><code>BACKEND_URL=$(az containerapp show \\\n  --name ca-rbtl-graphrag-backend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\necho \"Backend URL: https://$BACKEND_URL\"\n</code></pre>"},{"location":"operations/azure-deployment/#phase-4-frontend-docker-container-deployment","title":"Phase 4: Frontend Docker Container Deployment","text":""},{"location":"operations/azure-deployment/#41-build-and-push-frontend-docker-image","title":"4.1 Build and Push Frontend Docker Image","text":"<p>The frontend uses the <code>frontend/Dockerfile</code> to create a production-ready Next.js container:</p> <pre><code># Get backend URL first (from Phase 3.3)\nBACKEND_URL=$(az containerapp show \\\n  --name ca-rbtl-graphrag-backend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\n# Build frontend Docker image from frontend/Dockerfile\n# Pass backend URL as build argument for NEXT_PUBLIC_API_URL\ndocker build -f frontend/Dockerfile \\\n  --build-arg NEXT_PUBLIC_API_URL=https://$BACKEND_URL \\\n  -t acrrbtlgraphrag.azurecr.io/rbtl-graphrag-frontend:latest .\n\n# Tag with commit SHA for versioning\ndocker tag acrrbtlgraphrag.azurecr.io/rbtl-graphrag-frontend:latest \\\n  acrrbtlgraphrag.azurecr.io/rbtl-graphrag-frontend:$(git rev-parse --short HEAD)\n\n# Push both tags to ACR\ndocker push acrrbtlgraphrag.azurecr.io/rbtl-graphrag-frontend:latest\ndocker push acrrbtlgraphrag.azurecr.io/rbtl-graphrag-frontend:$(git rev-parse --short HEAD)\n</code></pre> <p>What the Dockerfile does: - Uses Node.js 18-alpine base image - Multi-stage build (deps \u2192 builder \u2192 runner) - Builds Next.js with standalone output mode - Creates optimized production image - Exposes port 3000</p>"},{"location":"operations/azure-deployment/#42-create-container-app-for-frontend","title":"4.2 Create Container App for Frontend","text":"<pre><code>az containerapp create \\\n  --name ca-rbtl-graphrag-frontend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --environment env-rbtl-graphrag-prod \\\n  --image acrrbtlgraphrag.azurecr.io/rbtl-graphrag-frontend:latest \\\n  --target-port 3000 \\\n  --ingress external \\\n  --registry-server acrrbtlgraphrag.azurecr.io \\\n  --registry-username $(az acr credential show --name acrrbtlgraphrag --query username -o tsv) \\\n  --registry-password $(az acr credential show --name acrrbtlgraphrag --query passwords[0].value -o tsv) \\\n  --min-replicas 1 \\\n  --max-replicas 3 \\\n  --cpu 0.5 \\\n  --memory 1.0Gi \\\n  --env-vars \\\n    NEXT_PUBLIC_API_URL=https://$BACKEND_URL\n</code></pre>"},{"location":"operations/azure-deployment/#43-get-frontend-url","title":"4.3 Get Frontend URL","text":"<pre><code>FRONTEND_URL=$(az containerapp show \\\n  --name ca-rbtl-graphrag-frontend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\necho \"Frontend URL: https://$FRONTEND_URL\"\n</code></pre>"},{"location":"operations/azure-deployment/#phase-5-cicd-pipeline-setup","title":"Phase 5: CI/CD Pipeline Setup","text":"<p>The GitHub Actions workflow (<code>.github/workflows/azure-deploy.yml</code>) fully automates the Docker build and deployment process:</p> <p>Automated Steps: 1. Backend:     - Builds Docker image from <code>backend/Dockerfile</code>    - Pushes to Azure Container Registry (ACR)    - Updates Container App with new image</p> <ol> <li>Frontend:</li> <li>Gets backend URL from deployed backend</li> <li>Builds Docker image from <code>frontend/Dockerfile</code> with backend URL</li> <li>Pushes to ACR</li> <li>Updates Container App with new image</li> </ol> <p>Workflow triggers on: - Pushes to <code>main</code> branch (changes to backend, frontend, ai, utils, or Dockerfiles) - Manual trigger via GitHub Actions UI</p>"},{"location":"operations/azure-deployment/#51-configure-github-secrets","title":"5.1 Configure GitHub Secrets","text":"<p>Add these secrets in GitHub repository settings:</p> <ul> <li><code>AZURE_CREDENTIALS</code>: Service principal credentials (create with <code>az ad sp create-for-rbac</code>)</li> <li><code>NEXT_PUBLIC_API_URL</code>: Your backend Container App URL (e.g., <code>https://ca-rbtl-graphrag-backend.xxx.azurecontainerapps.io</code>)</li> </ul>"},{"location":"operations/azure-deployment/#phase-6-monitoring-observability","title":"Phase 6: Monitoring &amp; Observability","text":""},{"location":"operations/azure-deployment/#61-enable-application-insights","title":"6.1 Enable Application Insights","text":"<pre><code>az monitor app-insights component create \\\n  --app ai-rbtl-graphrag-prod \\\n  --location westeurope \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --application-type web\n</code></pre>"},{"location":"operations/azure-deployment/#62-configure-logging","title":"6.2 Configure Logging","text":"<p>Add to Container App environment variables:</p> <pre><code>APPLICATIONINSIGHTS_CONNECTION_STRING=\"&lt;from-app-insights&gt;\"\n</code></pre>"},{"location":"operations/azure-deployment/#63-set-up-alerts","title":"6.3 Set Up Alerts","text":"<pre><code>az monitor metrics alert create \\\n  --name alert-backend-errors \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --scopes /subscriptions/&lt;sub-id&gt;/resourceGroups/rg-rbtl-graphrag-prod/providers/Microsoft.App/containerApps/ca-rbtl-graphrag-backend \\\n  --condition \"count ExceptionRate &gt; 5\" \\\n  --window-size 5m \\\n  --evaluation-frequency 1m\n</code></pre>"},{"location":"operations/azure-deployment/#phase-7-post-deployment-verification","title":"Phase 7: Post-Deployment Verification","text":""},{"location":"operations/azure-deployment/#71-health-check","title":"7.1 Health Check","text":"<pre><code>BACKEND_URL=$(az containerapp show \\\n  --name ca-rbtl-graphrag-backend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\ncurl https://$BACKEND_URL/api/health\n</code></pre>"},{"location":"operations/azure-deployment/#72-test-endpoints","title":"7.2 Test Endpoints","text":"<pre><code># Test chat endpoint\ncurl -X POST https://$BACKEND_URL/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"question\": \"Return 5 Person nodes\"}'\n\n# Test graph info\ncurl https://$BACKEND_URL/api/graph-info\n</code></pre>"},{"location":"operations/azure-deployment/#73-verify-frontend","title":"7.3 Verify Frontend","text":"<pre><code>FRONTEND_URL=$(az containerapp show \\\n  --name ca-rbtl-graphrag-frontend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --query properties.configuration.ingress.fqdn -o tsv)\n\necho \"Frontend URL: https://$FRONTEND_URL\"\n</code></pre> <ol> <li>Visit the frontend Container App URL</li> <li>Test chat interface</li> <li>Verify API connectivity</li> <li>Check browser console for errors</li> </ol>"},{"location":"operations/azure-deployment/#rollback-procedures","title":"Rollback Procedures","text":""},{"location":"operations/azure-deployment/#backend-rollback","title":"Backend Rollback","text":"<pre><code># List revisions\naz containerapp revision list \\\n  --name ca-rbtl-graphrag-backend \\\n  --resource-group rg-rbtl-graphrag-prod\n\n# Activate previous revision\naz containerapp revision activate \\\n  --name ca-rbtl-graphrag-backend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --revision &lt;previous-revision-name&gt;\n</code></pre>"},{"location":"operations/azure-deployment/#frontend-rollback","title":"Frontend Rollback","text":"<pre><code># List revisions\naz containerapp revision list \\\n  --name ca-rbtl-graphrag-frontend \\\n  --resource-group rg-rbtl-graphrag-prod\n\n# Activate previous revision\naz containerapp revision activate \\\n  --name ca-rbtl-graphrag-frontend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --revision &lt;previous-revision-name&gt;\n</code></pre>"},{"location":"operations/azure-deployment/#security-checklist","title":"Security Checklist","text":"<ul> <li>[ ] All secrets stored in Azure Key Vault</li> <li>[ ] HTTPS enforced on all endpoints</li> <li>[ ] CORS configured correctly</li> <li>[ ] Container images scanned for vulnerabilities</li> <li>[ ] Managed identity used for Key Vault access</li> <li>[ ] Network security groups configured (if using VNet)</li> <li>[ ] Application Insights logging enabled</li> <li>[ ] Regular security updates scheduled</li> </ul>"},{"location":"operations/azure-deployment/#maintenance","title":"Maintenance","text":""},{"location":"operations/azure-deployment/#regular-tasks","title":"Regular Tasks","text":"<ol> <li>Weekly: Review Application Insights for errors and performance</li> <li>Monthly: Update dependencies and container images</li> <li>As needed: Rotate API keys and secrets</li> </ol>"},{"location":"operations/azure-deployment/#updates","title":"Updates","text":"<pre><code># Update backend\naz containerapp update \\\n  --name ca-rbtl-graphrag-backend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --image acrrbtlgraphrag.azurecr.io/rbtl-graphrag-backend:latest\n\n# Update frontend\naz containerapp update \\\n  --name ca-rbtl-graphrag-frontend \\\n  --resource-group rg-rbtl-graphrag-prod \\\n  --image acrrbtlgraphrag.azurecr.io/rbtl-graphrag-frontend:latest\n\n# Or rebuild and push new images, then update (handled automatically by GitHub Actions)\n</code></pre>"},{"location":"operations/azure-deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/azure-deployment/#backend-not-starting","title":"Backend Not Starting","text":"<ol> <li>Check Container App logs: Azure Portal \u2192 Container App \u2192 Log stream</li> <li>Verify Key Vault secrets are accessible</li> <li>Check environment variables are correctly set</li> <li>Review Application Insights for errors</li> </ol>"},{"location":"operations/azure-deployment/#frontend-cant-connect-to-backend","title":"Frontend Can't Connect to Backend","text":"<ol> <li>Verify <code>NEXT_PUBLIC_API_URL</code> is set correctly</li> <li>Check CORS settings in backend</li> <li>Verify backend Container App is running</li> <li>Check network connectivity</li> </ol>"},{"location":"operations/azure-deployment/#next-steps","title":"Next Steps","text":"<p>After successful deployment:</p> <ol> <li>Set up staging environment for testing before production</li> <li>Configure backup strategies for Cosmos DB</li> <li>Implement disaster recovery plan</li> <li>Set up performance testing in CI/CD</li> <li>Document runbooks for common issues</li> </ol>"},{"location":"operations/deployment/","title":"Deployment & Environments","text":""},{"location":"operations/deployment/#deployment-environments","title":"Deployment &amp; Environments","text":"<p>This guide covers deploying the dockerized RBTL GraphRAG application across different environments.</p>"},{"location":"operations/deployment/#environment-matrix","title":"Environment Matrix","text":"Target Backend Frontend Neo4j MongoDB Langfuse Local Docker Container Docker Container Aura/self-hosted Atlas/local docker-compose Staging Docker (Azure Container Apps) Docker (Azure Container Apps) Managed Aura Managed Atlas Self-hosted or Cloud Prod Docker (Azure Container Apps) Docker (Azure Container Apps) Aura Enterprise Atlas/DocumentDB Langfuse Cloud <p>All environments use Docker containers for consistency and easy deployment.</p>"},{"location":"operations/deployment/#dockerized-deployment","title":"Dockerized Deployment","text":"<p>The application is fully containerized using Docker for all environments. This ensures consistency between local development, staging, and production.</p>"},{"location":"operations/deployment/#container-architecture","title":"Container Architecture","text":"<p>Backend Container (<code>backend/Dockerfile</code>): - Python 3.13-slim base image - All dependencies from <code>backend/requirements.txt</code> - Exposes port 8000 - Includes health check support - Multi-stage build for optimization</p> <p>Frontend Container (<code>frontend/Dockerfile</code>): - Node.js 18-alpine base image - Multi-stage build for optimization - Next.js standalone output mode - Exposes port 3000 - Production-ready static assets</p>"},{"location":"operations/deployment/#local-docker-setup","title":"Local Docker Setup","text":"<p>Quick Start: </p><pre><code># Production mode (optimized, no hot-reload)\ndocker-compose up --build\n\n# Development mode (with hot-reload for active coding)\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up --build\n</code></pre><p></p> <p>Access: - Frontend: http://localhost:3003 - Backend: http://localhost:8001 - API Docs: http://localhost:8001/docs</p> <p>See Docker Deployment Guide for detailed instructions, troubleshooting, and cloud deployment options.</p>"},{"location":"operations/deployment/#secrets-config","title":"Secrets &amp; Config","text":"<ul> <li>Store <code>.env</code> values in a secret manager (AWS Secrets Manager, Doppler, 1Password).</li> <li>Rotate OpenAI/Langfuse keys regularly; the backend reads them on startup.</li> <li>When running analytics agent, ensure both the backend and the MCP server agree on Neo4j credentials.</li> </ul>"},{"location":"operations/deployment/#environment-switching","title":"Environment Switching","text":"<p>The application supports switching between development and production environments using the <code>ENVIRONMENT</code> variable:</p> <ul> <li>Production: Set <code>ENVIRONMENT=production</code> (or omit it). Uses standard variables (<code>NEO4J_URI</code>, <code>MONGODB_URI</code>, etc.)</li> <li>Development: Set <code>ENVIRONMENT=development</code>. Uses <code>_DEV</code> suffixed variables (<code>NEO4J_URI_DEV</code>, <code>MONGODB_URI_DEV</code>, etc.)</li> </ul> <p>This allows you to: - Use local databases for development while keeping production credentials - Switch environments without changing code - Fallback to production values if <code>_DEV</code> variables are not set</p> <p>See Docker Deployment Guide for detailed configuration examples.</p>"},{"location":"operations/deployment/#observability-health-checks","title":"Observability &amp; Health Checks","text":"<ul> <li><code>GET /health</code> for FastAPI readiness.</li> <li>Langfuse dashboards for LLM traces; configure alerting on latency, failure rate.</li> <li>Add metrics/structured logs (planned).</li> </ul>"},{"location":"operations/deployment/#github-pages-mkdocs","title":"GitHub Pages + MkDocs","text":"<ul> <li><code>mkdocs build</code> produces static docs for GitHub Pages.</li> <li><code>mkdocs gh-deploy --force</code> publishes to <code>gh-pages</code>.</li> <li>Recommended GitHub Action (to be added) runs on pushes to <code>main</code> and pull requests for validation.</li> </ul>"},{"location":"operations/docs/","title":"Documentation Ops","text":""},{"location":"operations/docs/#documentation-ops","title":"Documentation Ops","text":"<p>This page captures the tooling and automation required to publish the MkDocs site to GitHub Pages.</p>"},{"location":"operations/docs/#local-tooling","title":"Local Tooling","text":"<p>Install (or update) the project dependencies, which now include the documentation toolchain:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Key packages:</p> <ul> <li><code>mkdocs</code> \u2013 static site generator</li> <li><code>mkdocs-material</code> \u2013 UI theme</li> <li><code>mkdocs-mermaid2-plugin</code> \u2013 renders Mermaid diagrams (e.g., architecture flowcharts)</li> <li><code>mkdocs-glightbox</code> \u2013 lightbox support for future screenshots</li> <li><code>pymdown-extensions</code> \u2013 extra Markdown features (superfences, details blocks, etc.)</li> </ul> <p>Common commands:</p> <pre><code>mkdocs serve        # live reload at http://127.0.0.1:8000\nmkdocs build        # generate site/ directory\nmkdocs gh-deploy    # push to gh-pages (requires repo access)\n</code></pre> <p>Run <code>mkdocs build --strict</code> locally before opening a PR so broken links or warnings fail fast.</p>"},{"location":"operations/docs/#github-pages-workflow","title":"GitHub Pages Workflow","text":"<p>A workflow defined in <code>.github/workflows/docs.yml</code> handles validation and deployment:</p> <ol> <li>Triggers on pushes to <code>main</code> and on pull requests.</li> <li>Installs Python 3.11 and the consolidated <code>requirements.txt</code>.</li> <li>Runs <code>mkdocs build --strict</code> to catch issues early.</li> <li>On <code>main</code>, performs <code>mkdocs gh-deploy --force</code> to publish the <code>gh-pages</code> branch consumed by GitHub Pages.</li> </ol> <p>Enable Pages in the repo settings with source set to the <code>gh-pages</code> branch. Add the published URL to <code>site_url</code> (already configured in <code>mkdocs.yml</code>) and link it in <code>README.md</code> badges when ready.</p>"},{"location":"operations/docs/#contribution-tips","title":"Contribution Tips","text":"<ul> <li>Keep content changes close to the code they describe; update docs within the same PR when possible.</li> <li>Favor relative links (e.g., <code>[Testing](operations/testing.md)</code>) so navigation works locally and on GitHub.</li> <li>When adding diagrams, export them to <code>docs/assets/</code> and reference with relative paths to benefit from glightbox later.</li> </ul>"},{"location":"operations/testing/","title":"Testing Strategy","text":""},{"location":"operations/testing/#testing-strategy","title":"Testing Strategy","text":"<p>Testing currently focuses on scripted smoke tests plus manual validation through the chat UI. Content from <code>TESTING_GUIDE.md</code> lives here so the docs site is authoritative.</p>"},{"location":"operations/testing/#prerequisites","title":"Prerequisites","text":"<ul> <li><code>.env</code> populated with Neo4j, OpenAI, Langfuse, and MongoDB credentials.</li> <li>Python 3.13+ virtual environment activated (<code>source venv/bin/activate</code>).</li> <li>Node.js 18+ installed.</li> <li>Neo4j instance reachable; Langfuse stack running (via <code>docker-compose.langfuse.yml</code>) if prompts are fetched from Langfuse.</li> </ul>"},{"location":"operations/testing/#scripted-workflow","title":"Scripted Workflow","text":""},{"location":"operations/testing/#manual-bring-up","title":"Manual Bring-Up","text":"<ol> <li>Activate venv <pre><code>source venv/bin/activate\n</code></pre></li> <li>Install backend deps <pre><code>pip install -r requirements.txt\n</code></pre></li> <li>Start FastAPI <pre><code>uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000\n</code></pre></li> <li>Install frontend deps <pre><code>cd frontend\nnpm install\n</code></pre></li> <li>Create <code>frontend/.env.local</code> <pre><code>NEXT_PUBLIC_API_URL=http://localhost:8000\n</code></pre></li> <li>Run Next.js dev server <pre><code>npm run dev  # defaults to http://localhost:3000 (or 3002 based on port availability)\n</code></pre></li> </ol>"},{"location":"operations/testing/#manual-validation-scenarios","title":"Manual Validation Scenarios","text":"<ol> <li>Cypher Generation CLI <pre><code>python ai/text_to_cypher.py \"Return 5 Person nodes\"\nEXECUTE_CYPHER=true OUTPUT_MODE=json python ai/text_to_cypher.py \"Return 5 Person nodes\"\nEXECUTE_CYPHER=true OUTPUT_MODE=chat python ai/text_to_cypher.py \"Return 5 Person nodes\"\n</code></pre></li> <li>Chat UI</li> <li>Visit <code>http://localhost:3000</code>.</li> <li>Ask multi-turn questions, confirm progress cards indicate whether analytics agent was used.</li> <li>Knowledge Base</li> <li>Favorite or edit categories in the UI; verify MongoDB entries update.</li> <li>Langfuse Traces</li> <li>Check <code>http://localhost:3001</code> to confirm prompts and tool calls are recorded with the correct label.</li> </ol>"},{"location":"operations/testing/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Backend won\u2019t start: double-check env vars, ensure Neo4j credentials are valid, reinstall dependencies.</li> <li>Frontend can\u2019t reach backend: verify FastAPI is running on <code>http://localhost:8000</code>, update <code>NEXT_PUBLIC_API_URL</code>, and confirm CORS settings.</li> <li>API errors: read backend logs, test endpoints via curl/Postman, or hit <code>http://localhost:8000/docs</code>.</li> </ul>"},{"location":"operations/testing/#additional-testing","title":"Additional Testing","text":"<p>For MCP analytics agent verification, use <code>python ai/mcp_client.py --interactive</code> to manually test tool discovery and invocation.</p>"},{"location":"operations/testing/#future-work","title":"Future Work","text":"<ul> <li>Adopt pytest for backend unit/integration tests plus Playwright for frontend e2e.</li> <li>Run scripts inside CI pipelines that gate merges.</li> <li>Capture fixture graph snapshots for deterministic regression tests.</li> </ul>"},{"location":"reference/api/","title":"API Surface","text":""},{"location":"reference/api/#api-reference","title":"API Reference","text":"<p>The GraphRAG backend exposes a FastAPI REST API for querying Neo4j graph databases using natural language. All endpoints are prefixed with <code>/api</code> except for the root and health endpoints.</p>"},{"location":"reference/api/#interactive-api-documentation","title":"Interactive API Documentation","text":"<p>FastAPI automatically generates interactive API documentation that you can use to explore and test endpoints:</p> <ul> <li>Swagger UI: Available at <code>/docs</code> when the backend is running</li> <li>Local: http://localhost:8000/docs</li> <li>Docker: http://localhost:8001/docs</li> <li>ReDoc: Available at <code>/redoc</code> when the backend is running</li> <li>Local: http://localhost:8000/redoc</li> <li>Docker: http://localhost:8001/redoc</li> </ul> <p>The interactive docs include: - Complete request/response schemas - Try-it-out functionality to test endpoints directly - Authentication requirements (if configured) - Example payloads</p>"},{"location":"reference/api/#base-url","title":"Base URL","text":"<ul> <li>Local Development: <code>http://localhost:8000</code></li> <li>Docker: <code>http://localhost:8001</code></li> <li>Production: Configured per deployment environment</li> </ul>"},{"location":"reference/api/#endpoints","title":"Endpoints","text":""},{"location":"reference/api/#health-check","title":"Health Check","text":""},{"location":"reference/api/#get-apihealth","title":"<code>GET /api/health</code>","text":"<p>Health check endpoint for monitoring and deployment probes.</p> <p>Response: </p><pre><code>{\n  \"status\": \"healthy\",\n  \"service\": \"graphrag-api\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#chat-endpoints","title":"Chat Endpoints","text":""},{"location":"reference/api/#post-apichat","title":"<code>POST /api/chat</code>","text":"<p>Main chat interface for processing natural language questions and returning Cypher queries with results.</p> <p>Request Body: </p><pre><code>{\n  \"username\": \"bojan\",\n  \"question\": \"How many TikTok users have over 1 million followers?\",\n  \"execute_cypher\": true,\n  \"output_mode\": \"chat\"\n}\n</code></pre><p></p> <p>Parameters: - <code>username</code> (string, required): Tester username (must be in allowed list) - <code>question</code> (string, required): Natural language question - <code>execute_cypher</code> (boolean, default: <code>true</code>): Whether to execute the generated Cypher query - <code>output_mode</code> (string, default: <code>\"chat\"</code>): Output format - <code>\"json\"</code>, <code>\"chat\"</code>, or <code>\"both\"</code></p> <p>Response: </p><pre><code>{\n  \"username\": \"bojan\",\n  \"question\": \"How many TikTok users have over 1 million followers?\",\n  \"route_type\": \"cypher\",\n  \"cypher\": \"MATCH (t:TikTokUser) WHERE t.follower_count &gt; 1000000 RETURN count(t) as count\",\n  \"results\": [{\"count\": 42}],\n  \"summary\": \"There are 42 TikTok users with over 1 million followers.\",\n  \"examples_used\": [...],\n  \"timings\": {\n    \"similar_queries\": 0.5,\n    \"generate_cypher\": 2.3,\n    \"query_knowledge_base\": 0.8,\n    \"generate_final_response\": 1.2\n  },\n  \"message_id\": \"uuid-here\"\n}\n</code></pre><p></p> <p>Response Fields: - <code>route_type</code>: Either <code>\"analytics\"</code> or <code>\"cypher\"</code> indicating which processing route was used - <code>cypher</code>: Generated Cypher query (if route_type is \"cypher\") - <code>tool_name</code>: Analytics tool name (if route_type is \"analytics\") - <code>tool_inputs</code>: Analytics tool parameters (if route_type is \"analytics\") - <code>results</code>: Query results from Neo4j - <code>summary</code>: Natural language summary of results - <code>examples_used</code>: Similar query examples used for few-shot learning - <code>timings</code>: Performance metrics for each processing step - <code>message_id</code>: Unique identifier for the stored message</p>"},{"location":"reference/api/#get-apichatusers","title":"<code>GET /api/chat/users</code>","text":"<p>Return list of available tester usernames.</p> <p>Response: </p><pre><code>{\n  \"users\": [\"bojan\", \"roel\", \"famke\", \"scarlett\"]\n}\n</code></pre><p></p>"},{"location":"reference/api/#get-apichathistoryusername","title":"<code>GET /api/chat/history/{username}</code>","text":"<p>Retrieve stored chat history for a specific user.</p> <p>Path Parameters: - <code>username</code> (string): Tester username</p> <p>Response: </p><pre><code>{\n  \"username\": \"bojan\",\n  \"messages\": [\n    {\n      \"id\": \"message-id\",\n      \"role\": \"user\",\n      \"content\": \"Question text\",\n      \"timestamp\": \"2024-01-01T12:00:00\",\n      \"is_favorite\": false\n    },\n    {\n      \"id\": \"message-id\",\n      \"role\": \"assistant\",\n      \"content\": \"Response text\",\n      \"cypher\": \"MATCH ...\",\n      \"results\": [...],\n      \"summary\": \"Summary text\",\n      \"timestamp\": \"2024-01-01T12:00:01\",\n      \"is_favorite\": false\n    }\n  ]\n}\n</code></pre><p></p>"},{"location":"reference/api/#delete-apichathistoryusernamemessage_id","title":"<code>DELETE /api/chat/history/{username}/{message_id}</code>","text":"<p>Delete a specific message from a user's chat history.</p> <p>Path Parameters: - <code>username</code> (string): Tester username - <code>message_id</code> (string): Message ID to delete</p> <p>Response: </p><pre><code>{\n  \"message\": \"Message deleted\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#post-apichatfavoritesusernamemessage_id","title":"<code>POST /api/chat/favorites/{username}/{message_id}</code>","text":"<p>Mark or unmark a message as favorite.</p> <p>Path Parameters: - <code>username</code> (string): Tester username - <code>message_id</code> (string): Message ID</p> <p>Request Body: </p><pre><code>{\n  \"is_favorite\": true\n}\n</code></pre><p></p> <p>Response: </p><pre><code>{\n  \"message\": \"Favorite updated\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#get-apichatfavoritesusername","title":"<code>GET /api/chat/favorites/{username}</code>","text":"<p>Retrieve all favorite messages for a user.</p> <p>Path Parameters: - <code>username</code> (string): Tester username</p> <p>Response: </p><pre><code>{\n  \"username\": \"bojan\",\n  \"favorites\": [\n    {\n      \"message\": {\n        \"id\": \"message-id\",\n        \"role\": \"assistant\",\n        \"content\": \"Response text\",\n        \"cypher\": \"MATCH ...\",\n        \"timestamp\": \"2024-01-01T12:00:00\",\n        \"is_favorite\": true\n      },\n      \"question\": \"Original question\",\n      \"question_id\": \"question-id\"\n    }\n  ]\n}\n</code></pre><p></p>"},{"location":"reference/api/#get-apichatanalytics-tools","title":"<code>GET /api/chat/analytics-tools</code>","text":"<p>Return available graph analytics tools and their descriptions.</p> <p>Response: </p><pre><code>{\n  \"tools\": [\n    {\n      \"name\": \"leiden\",\n      \"description\": \"Community detection using Leiden algorithm\",\n      \"keywords\": [\"community\", \"cluster\", \"group\"],\n      \"defaults\": {...}\n    },\n    {\n      \"name\": \"article_rank\",\n      \"description\": \"Influence ranking using ArticleRank\",\n      \"keywords\": [\"influence\", \"rank\", \"important\"],\n      \"defaults\": {...}\n    }\n  ],\n  \"note\": \"These tools are available for graph analytics questions...\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#ws-apichatstream","title":"<code>WS /api/chat/stream</code>","text":"<p>WebSocket endpoint for streaming chat responses in real-time.</p> <p>Connection: </p><pre><code>const ws = new WebSocket('ws://localhost:8001/api/chat/stream');\n</code></pre><p></p> <p>Send Message: </p><pre><code>{\n  \"username\": \"bojan\",\n  \"question\": \"How many people are there?\",\n  \"execute_cypher\": true,\n  \"output_mode\": \"chat\"\n}\n</code></pre><p></p> <p>Receive Messages: </p><pre><code>{\"type\": \"status\", \"message\": \"Processing question...\"}\n{\"type\": \"cypher\", \"cypher\": \"MATCH (p:Person) RETURN count(p)\"}\n{\"type\": \"results\", \"results\": [{\"count\": 1000}]}\n{\"type\": \"summary\", \"summary\": \"There are 1000 people in the graph.\"}\n{\"type\": \"complete\"}\n</code></pre><p></p>"},{"location":"reference/api/#graph-information-endpoints","title":"Graph Information Endpoints","text":""},{"location":"reference/api/#get-apigraph-info","title":"<code>GET /api/graph-info</code>","text":"<p>Return cached graph schema overview including nodes, relationships, and terminology.</p> <p>Response: </p><pre><code>{\n  \"schema_text\": \"Node properties:\\n:`Person` {...}\",\n  \"terminology_text\": \"Terminology definitions...\",\n  \"nodes\": [\n    {\n      \"label\": \"Person\",\n      \"properties\": [\n        {\"property\": \"age\", \"type\": \"String\"},\n        {\"property\": \"gender\", \"type\": \"String\"}\n      ],\n      \"description\": \"A person in the graph\"\n    }\n  ],\n  \"relationships\": [\n    {\n      \"start\": \"Person\",\n      \"type\": \"FOLLOWS\",\n      \"end\": \"Influencer\",\n      \"description\": \"Person follows an influencer\"\n    }\n  ],\n  \"graph_ready\": true,\n  \"summary\": \"This overview is generated from the cached schema...\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#get-apigraph-visualization","title":"<code>GET /api/graph-visualization</code>","text":"<p>Return the static schema visualization JSON file for rendering graph diagrams.</p> <p>Response: </p><pre><code>{\n  \"nodes\": [...],\n  \"relationships\": [...],\n  \"visualization\": {...}\n}\n</code></pre><p></p>"},{"location":"reference/api/#knowledge-base-endpoints","title":"Knowledge Base Endpoints","text":""},{"location":"reference/api/#get-apiknowledge-basecategories","title":"<code>GET /api/knowledge-base/categories</code>","text":"<p>Retrieve all query categories from the knowledge base.</p> <p>Response: </p><pre><code>[\n  {\n    \"category_name\": \"Entity lookup and profiling\",\n    \"category_description\": \"Queries that retrieve entity information...\"\n  }\n]\n</code></pre><p></p>"},{"location":"reference/api/#get-apiknowledge-basequeriescategorycategory_name","title":"<code>GET /api/knowledge-base/queries?category={category_name}</code>","text":"<p>Retrieve query examples for a specific category.</p> <p>Query Parameters: - <code>category</code> (string, required): Category name</p> <p>Response: </p><pre><code>[\n  {\n    \"question\": \"Return all Person nodes with their properties\",\n    \"cypher\": \"MATCH (p:Person) RETURN p LIMIT 100\",\n    \"added_at\": \"2024-01-01T12:00:00\",\n    \"created_by\": \"user\"\n  }\n]\n</code></pre><p></p>"},{"location":"reference/api/#post-apiknowledge-basequeries","title":"<code>POST /api/knowledge-base/queries</code>","text":"<p>Add a new query example to a category.</p> <p>Request Body: </p><pre><code>{\n  \"category_name\": \"Entity lookup and profiling\",\n  \"question\": \"Find all verified TikTok users\",\n  \"cypher\": \"MATCH (t:TikTokUser) WHERE t.is_verified = true RETURN t\",\n  \"created_by\": \"user\"\n}\n</code></pre><p></p> <p>Response: </p><pre><code>{\n  \"message\": \"Query added successfully\",\n  \"example\": {\n    \"question\": \"Find all verified TikTok users\",\n    \"cypher\": \"MATCH (t:TikTokUser) WHERE t.is_verified = true RETURN t\",\n    \"added_at\": \"2024-01-01T12:00:00\",\n    \"created_by\": \"user\"\n  }\n}\n</code></pre><p></p>"},{"location":"reference/api/#put-apiknowledge-basequeriescategorycategory_name","title":"<code>PUT /api/knowledge-base/queries?category={category_name}</code>","text":"<p>Update an existing query example.</p> <p>Query Parameters: - <code>category</code> (string, required): Category name</p> <p>Request Body: </p><pre><code>{\n  \"old_question\": \"Original question\",\n  \"old_cypher\": \"MATCH ...\",\n  \"new_question\": \"Updated question\",\n  \"new_cypher\": \"MATCH ...\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#delete-apiknowledge-basequeriescategorycategory_name","title":"<code>DELETE /api/knowledge-base/queries?category={category_name}</code>","text":"<p>Delete a query example from a category.</p> <p>Query Parameters: - <code>category</code> (string, required): Category name</p> <p>Request Body: </p><pre><code>{\n  \"question\": \"Question to delete\",\n  \"cypher\": \"Cypher to delete\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#get-apiknowledge-basecategories_1","title":"<code>GET /api/knowledge-base/categories</code>","text":"<p>Retrieve all categories (same as <code>/api/knowledge-base/categories</code>).</p>"},{"location":"reference/api/#post-apiknowledge-basecategories","title":"<code>POST /api/knowledge-base/categories</code>","text":"<p>Create a new category.</p> <p>Request Body: </p><pre><code>{\n  \"category_name\": \"New Category\",\n  \"category_description\": \"Description of the category\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#put-apiknowledge-basecategories","title":"<code>PUT /api/knowledge-base/categories</code>","text":"<p>Update an existing category.</p> <p>Request Body: </p><pre><code>{\n  \"category_name\": \"Category Name\",\n  \"category_description\": \"Updated description\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#delete-apiknowledge-basecategoriescategorycategory_name","title":"<code>DELETE /api/knowledge-base/categories?category={category_name}</code>","text":"<p>Delete a category and all its query examples.</p> <p>Query Parameters: - <code>category</code> (string, required): Category name</p>"},{"location":"reference/api/#error-responses","title":"Error Responses","text":"<p>All endpoints may return standard HTTP error responses:</p> <ul> <li><code>400 Bad Request</code>: Invalid request parameters</li> <li><code>403 Forbidden</code>: Username not in allowed list</li> <li><code>404 Not Found</code>: Resource not found</li> <li><code>500 Internal Server Error</code>: Server error</li> </ul> <p>Error Response Format: </p><pre><code>{\n  \"detail\": \"Error message describing what went wrong\"\n}\n</code></pre><p></p>"},{"location":"reference/api/#authentication","title":"Authentication","text":"<p>Currently, the API uses username-based access control. Only usernames in the allowed tester list can access chat endpoints. This is configured in <code>backend/app/services/chat_sessions.py</code>.</p> <p>Future versions may include: - API key authentication - OAuth2 integration - Role-based access control</p>"},{"location":"reference/api/#rate-limiting","title":"Rate Limiting","text":"<p>Rate limiting is not currently implemented but may be added in future versions.</p>"},{"location":"reference/api/#openapi-specification","title":"OpenAPI Specification","text":"<p>The complete OpenAPI 3.0 specification is available at <code>/openapi.json</code> when the backend is running. This can be used to: - Generate client SDKs - Import into API testing tools (Postman, Insomnia) - Generate additional documentation</p>"},{"location":"reference/glossary/","title":"Glossary (Draft)","text":""},{"location":"reference/glossary/#glossary-draft","title":"Glossary (Draft)","text":"<p>This glossary will eventually be auto-generated from <code>ai/terminology/*.yaml</code>. For now, it mirrors key concepts the team uses in prompts and discussions.</p> <ul> <li>GraphRAG \u2013 Graph Retrieval-Augmented Generation system that converts natural language to Cypher.</li> <li>Langfuse \u2013 Observability and prompt management platform used for tracing and versioning LLM calls.</li> <li>MCP (Model Context Protocol) \u2013 Standard for tool/agent interoperability; GraphRAG uses it to talk to the Neo4j GDS Agent.</li> <li>Analytics Agent \u2013 Optional routing path that invokes GDS algorithms (community detection, influence, etc.) instead of plain Cypher.</li> <li>Knowledge Base \u2013 MongoDB-backed store for curated insights, categories, and favorites surfaced in the UI.</li> <li>Few-shot Examples \u2013 JSON snippets that prime the LLM with representative queries per category.</li> </ul> <p>Todo: Add script that imports <code>ai/terminology/v1.yaml</code> and renders a table here during docs build.</p>"}]}